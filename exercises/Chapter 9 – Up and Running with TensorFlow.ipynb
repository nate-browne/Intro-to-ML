{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up and Running with TensorFlow\n",
    "\n",
    "*TensorFlow* is a powerful open-source software library for numerical computation, particularly well suited and fine-tuned for large-scale machine learning. Its basic principle is simple; first define in Python a graph of computations to perform, and then TensorFlow takes the graph and runs it efficiently using optimized C++.\n",
    "\n",
    "Most importantly, it's possible to break the graph into several chunks and run them in parallel across multiple CPUs/GPUs. TensorFlow also supports distributed computing, so you can train colossal neural networks on humongous training sets in a reasonable amount of time by splitting the computations across hundreds of servers (see chapter 12). TensorFlow can train a network with millions of parameters on a training set composed of billions of instances with millions of features each. This shouldn't be a surprise, since TensorFlow was developed by Google's Brain team and powers many things like Google Cloud Speech, Google Photos, and Google Search\n",
    "\n",
    "Here's a table of open source Deep Learning libraries available (not exhaustive):\n",
    "\n",
    "Library | API | Platforms | Started by | Year\n",
    "--- | --- | --- | --- | ---\n",
    "Caffe | Python, C++, Matlab | Linux, macOS, Windows | y, Jia, UC Berkeley | 2013\n",
    "Deeplearning4j | Java, Scala, Clojure | Linux, macOS, Windows, Android | A. Gibson, J. Patterson | 2014\n",
    "H20 | Python, R | Linux, macOS, Windows | H20.ai | 2014\n",
    "MXNet | Python, C++, others | Linux, macOS, Windows, iOS, Android | DMLC | 2015\n",
    "TensorFlow | Python, C++ | Linux, macOS, Windows, iOS, Android | Google | 2015\n",
    "Theano | Python | Linux, macOS, iOS | University of Montreal | 2010\n",
    "Torch | C++, Lua | Linux, macOS, iOS, Android | R. Collobert, K. Kavukcuoglu, C. Farabet | 2002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Your First Graph and Running It in a Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, you can create an interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A TensorFlow program is typically split into two parts: the first part builds a computation graph (this is called the *construction phase*), and the second part runs it (this is called the *execution phase*). The construction phase typically builds a computation graph represeting the ML model and the computations required to train it. The execution phase generally runs a loop that evaluates a training step repeatedly (for example, one step per mmini-batch), gradually improving the model parameters. WE well go through an example shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Graphs\n",
    "\n",
    "Any node you create is automatically added to the default graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fine in most cases, but sometimes you may want to manage multiple independent graphs. This can be done by creating a new `Graph` and temporariliy making it the default graph inside of a `with` block, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    \n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: in Jupyter (and in a Python shell) it's common to run the same commands repeatedly when experimenting. As a result, you may end up with a default graph containing multiple duplicate nodes. One solution is to restart the Jupyter kernel/Python shell, but a more convenient solution is to just reset the default graph by running `tf.reset_default_graph()`*\n",
    "\n",
    "## Lifecycle of a Node Value\n",
    "\n",
    "When you evaluate a node, TensorFlow automatically determines the set of nodes that it depends on and it evalutes those nodes first. For example, consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) # 10\n",
    "    print(z.eval()) # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, this code defines a simple graph. Then it starts a session and runs the graph to evaluate `y`; TensorFlow will detect that `y` depends on `x` and that `x` depends on `w`, so it first will evaluate `w`, then `x`, then `y`, then returns the value of `y`. Finally, it will execute `z`. Once again, it detects that it needs `w` and `x`, but it *__will not__* reuse the result of the previous evaluation. In short, the above code evalutes the values of `x` and `w` twice.\n",
    "\n",
    "All node values are dropped between graph runs, except variable values, which are maintained by the session across graph runs. A variable starts its life when its initializer (constructor) is run, and ends when the session is closed.\n",
    "\n",
    "If you want to evalute `y` and `z` efficiently without evaluating `w` and `x` twice (like the previous code) you must ask Tensorflow to evaluate both `y` and `z` in just one graph run, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: in single-process TensorFlow, multiple sessions don't share any state, even if they reuse the same graph. In distributed TensorFlow (see chapter 12), variable state is stored on the servers, not in the sessions, so multiple sessions can share the same variables.\n",
    "\n",
    "## Linear Regression with TensorFlow\n",
    "\n",
    "TensorFlow operations (known as *ops* for short), can take any number of inputs and produce any number of outputs. For example, addition and multiplication both take two inputs and produce one output. Constants and variables are known as *source ops* (ops that take no input). The inputs and outputs are multidimensional arrays known as *tensors*. Just like Numpy arrays, tensors have a type and shape (in fact, the Python API tensors are just Numpy ndarrays. They typically contain floats, but you can use them to carry strings as well (arbitrary byte arrays)).\n",
    "\n",
    "In our examples, the tensors have just contained a single scalar value, but you can (obviously) perform computations on arrays of any shape.\n",
    "\n",
    "The following code performs Linear Regression on the California housing data from earlier by manipulating 2D arrays. It starts by fetching the data, then adding an extra bias input feature to all training instances using Numpy, then it creates two TensorFlow constant nodes `X` and `y`, to hold this data and the targets, and it uses some matrix operations provided by TensorFlow to define `theta`. You may recognize that `theta` is the Normal Equation ($\\hat{\\theta} = (\\textbf{X}^T\\cdot\\textbf{X})^{-1}\\cdot\\textbf{X}^T\\cdot y$; see chapter 4)Finally, the code creates a session and evaluates `theta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /Users/nate_browne/scikit_learn_data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-3.7185181e+01],\n",
       "       [ 4.3633747e-01],\n",
       "       [ 9.3952334e-03],\n",
       "       [-1.0711310e-01],\n",
       "       [ 6.4479220e-01],\n",
       "       [-4.0338000e-06],\n",
       "       [-3.7813708e-03],\n",
       "       [-4.2348403e-01],\n",
       "       [-4.3721911e-01]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from os.path import expanduser\n",
    "\n",
    "housing = fetch_california_housing(data_home=expanduser('~/Coding Stuff/Python/handson-ml/datasets'))\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "theta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654266e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy version of what we just did\n",
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "theta_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69419202e+01]\n",
      " [ 4.36693293e-01]\n",
      " [ 9.43577803e-03]\n",
      " [-1.07322041e-01]\n",
      " [ 6.45065694e-01]\n",
      " [-3.97638942e-06]\n",
      " [-3.78654265e-03]\n",
      " [-4.21314378e-01]\n",
      " [-4.34513755e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# scikit learn version\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing.data, housing.target.reshape(-1, 1))\n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main benefit of this code vs using Numpy to compute the Normal Equation is that TensorFlow will use your GPU if you have one (providing you installed TensorFlow with GPU support (see chapter 12)).\n",
    "\n",
    "## Implementing Gradient Descent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
