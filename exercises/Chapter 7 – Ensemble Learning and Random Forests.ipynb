{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Random Forests\n",
    "\n",
    "Suppose you ask a complex question to thousands of random people, the aggregate their answers. You'll often find that this answer is better than an expert's answer. This is known as the *wisdom of the crowd*. In ML, aggregating the predictions of a group of predictors will often yield better predictions than with the best individual predictor. A group of predictors is known as an *ensemble*; thus, this technique is known as *Ensemble Learning*. (An ensemble learning algo is known as an *Ensemble method*).\n",
    "\n",
    "An example is training a group of Decision Trees, each on a different subset of the training set. To make predictions, you just obtain the predictions of all of the individual trees, then predict the class that gets the most votes (see the last exercise of the previous chapter for an example). Such an ensemble of Decision Trees is known as a *Random Forest*, and despite the simplicity, is one of the most powerful ML algos available today.\n",
    "\n",
    "Moreover, as discussed in chapter 2, Ensemble methods are often used near the en of a project once a few good predictors have been built to combine them into an even better one.\n",
    "\n",
    "In this section, we'll cover some of the popular Ensemble methods (such as *bagging*, *boosting*, *stacking*, and some others) as well as Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifiers\n",
    "\n",
    "Let's say you've trained a few classifiers, each reaching about 80% accuracy. You may have a Logistic Regression, SVM, Random Forest, K-Nearest Neighbors, and maybe some more. A simple way to create an even better classifier is to aggregate the predictions of each classifier and predict the class that gets the most votes. This majority-vote classifier is called a *hard voting* classifier.\n",
    "\n",
    "Surprisingly, this classifier often achieves higher accuracy than the best classifier in the ensemble. In fact, even if each classifier is a *weak learner* (it does only slightly better than random guessing), the ensemble can still be a *strong learner* (achieving high accuracy) provided there are sufficient number of weak learners and they are sufficiently diverse. This is possible because of the *law of large numbers*.\n",
    "\n",
    "*Note: ensemble methods work best when the predictors are as independent from one another as possible. One way to get this is to train the classifiers using very different algos. This increases the chance that they will make very different types of errors, improving the ensemble's accuracy.*\n",
    "\n",
    "The following code creates and trains a voting classifier in sklearn, composed of three diverse classifiers. We'll use the moons dataset for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomFor...f',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Grab and separate the data\n",
    "X, y = make_moons(n_samples=500, noise=0.3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.872\n",
      "SVC 0.888\n",
      "VotingClassifier 0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VotingClassifier is just slightly worse than the SVC in our case! If all classifiers have the `predict_proba()` method implemented, then you can tell sklearn to predict the class with the highest class probability, averaged over all the individual classifiers. This is known as *soft voting*. It often does better than hard voting because it gives more weight to highly confident votes. To do this, all we need to do is replace the `voting='hard'` with `voting='soft'` in the parameter list and ensure that all classifiers used have that method implemented. This is not the case of `SVC` by default, so the `probability` hyperparameter needs to be set to `True` (which makes the `SVC` class do cross-validation to estimate probabilities, slowing down training, and it will add a `predict_proba()` method). Let's do that now and check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42, probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Pasting\n",
    "\n",
    "Another approach for getting a diverse set of classifiers is to use the same training algo for each predictor, but to train them on different random subsets of the training set. When done *with* replacement, this is known as [bagging](https://goo.gl/o42tml) which is short for *bootstrap aggregating*. When sampling is performed *without* replacement, it is called [pasting](https://goo.gl/BXm0pm).\n",
    "\n",
    "In other words, both methods allow training instances to be sampled several times across multiple predictors, but only bagging allows training instance to be sampled several time for the same predictor.\n",
    "\n",
    "Once all predictors are trained, the ensemble can make a new prediction for an incoming instance by aggregating the predictions of the predictors. The aggregation function is typically the *statistical mode* for classification, or the *statistical mean/average* for regression. Each individual predictor has a higher bias than if it were trained on the original training set, but aggregating reduces both bias and variance. Generally the net result is that the ensemble has a similar bias but a lower variance than a single predictor trained on the original training set.\n",
    "\n",
    "These methods are popular because they can be used to train in parallel on different threads/CPU cores/servers. Predictions can also be made in parallel, making these methods highly scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Pasting in Scikit-Learn\n",
    "\n",
    "Sklearn has a simple set of classes for both bagging and pasting using the `BaggingClassifier` class (or `BaggingRegressor`). The following code trains an ensemble of 500 Decision Trees each trained on 100 training instances randomly sampled with replacement (so we're using bagging here). If you want pasting, use `bootstrap=False`. The `n_jobs` param tells sklearn how many cores to use for training and prediction (-1 means \"use all available\"):\n",
    "\n",
    "*Note: the `BaggingClassifer` automatically performs soft voting if the base classifier can estimate class probabilities (has a `predict_proba` method).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "                           max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping adds a bit more diversity into the subsets that each predictor is trained on, so bagging ends up with a slightly higher bias than pasting (but this also means that predictors end up being less correlated so the ensemble's variance is reduced). Overall, bagging often results in better models, which explains why it is (generally) preferred. However, if you have spair time and CPU power you can cross-validate to evaluate both bagging and pasting and select the better one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Bag Evaluation\n",
    "\n",
    "With bagging, some instances may be sampled several times for any given predictor whilst others may not be sampled at all. By default, a `BaggingClassifier` samples $m$ training instances with replacement (`bootstrap=True`) where $m$ is the size of the training set. This means that only ~63% of the training instances are sampled on average for each predictor. The rest that aren't sampled are called *out-of-bag* (oob) instances.\n",
    "\n",
    "Since a predictor never sees these instances during training, it can be evaluated on them wihtout the need for separate validation set/cross validation. You can evaluate the ensemble itself by averaging out the oob predictions of each predictor.\n",
    "\n",
    "Sklearn has the option to set `oob_score=True` when creating a `BaggingClassifier` to request automatic oob evaluation after training. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True, random_state=40)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our evaluations predicts us getting 90.1% accuracy on the test set. Let's check that\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "91% accuracy, not bad!\n",
    "\n",
    "The decision function for each training instance is available through the `oob_decision_function_` variable. In this case, (since the base estimator has a `predict_proba()` method) the decision function returns the class probabilities for each training instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31746032, 0.68253968],\n",
       "       [0.34117647, 0.65882353],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08379888, 0.91620112],\n",
       "       [0.31693989, 0.68306011],\n",
       "       [0.02923977, 0.97076023],\n",
       "       [0.97687861, 0.02312139],\n",
       "       [0.97765363, 0.02234637],\n",
       "       [0.74404762, 0.25595238],\n",
       "       [0.        , 1.        ],\n",
       "       [0.71195652, 0.28804348],\n",
       "       [0.83957219, 0.16042781],\n",
       "       [0.97777778, 0.02222222],\n",
       "       [0.0625    , 0.9375    ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97297297, 0.02702703],\n",
       "       [0.95238095, 0.04761905],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01704545, 0.98295455],\n",
       "       [0.38947368, 0.61052632],\n",
       "       [0.88700565, 0.11299435],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96685083, 0.03314917],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99428571, 0.00571429],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64804469, 0.35195531],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.13402062, 0.86597938],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.36065574, 0.63934426],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.27093596, 0.72906404],\n",
       "       [0.34146341, 0.65853659],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [0.98265896, 0.01734104],\n",
       "       [0.91428571, 0.08571429],\n",
       "       [0.97282609, 0.02717391],\n",
       "       [0.97029703, 0.02970297],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06134969, 0.93865031],\n",
       "       [0.98019802, 0.01980198],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97790055, 0.02209945],\n",
       "       [0.79473684, 0.20526316],\n",
       "       [0.41919192, 0.58080808],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.        , 1.        ],\n",
       "       [0.67613636, 0.32386364],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87356322, 0.12643678],\n",
       "       [1.        , 0.        ],\n",
       "       [0.56140351, 0.43859649],\n",
       "       [0.16304348, 0.83695652],\n",
       "       [0.67539267, 0.32460733],\n",
       "       [0.90673575, 0.09326425],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16201117, 0.83798883],\n",
       "       [0.89005236, 0.10994764],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.995     , 0.005     ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07272727, 0.92727273],\n",
       "       [0.05418719, 0.94581281],\n",
       "       [0.29533679, 0.70466321],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.81871345, 0.18128655],\n",
       "       [0.01092896, 0.98907104],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.22513089, 0.77486911],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9368932 , 0.0631068 ],\n",
       "       [0.76536313, 0.23463687],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.17127072, 0.82872928],\n",
       "       [0.65306122, 0.34693878],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03076923, 0.96923077],\n",
       "       [0.49444444, 0.50555556],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02673797, 0.97326203],\n",
       "       [0.98870056, 0.01129944],\n",
       "       [0.23121387, 0.76878613],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [0.98963731, 0.01036269],\n",
       "       [0.25641026, 0.74358974],\n",
       "       [0.92972973, 0.07027027],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.80681818, 0.19318182],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0106383 , 0.9893617 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01036269, 0.98963731],\n",
       "       [0.97752809, 0.02247191],\n",
       "       [0.99453552, 0.00546448],\n",
       "       [0.01960784, 0.98039216],\n",
       "       [0.18367347, 0.81632653],\n",
       "       [0.98387097, 0.01612903],\n",
       "       [0.29533679, 0.70466321],\n",
       "       [0.98295455, 0.01704545],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00561798, 0.99438202],\n",
       "       [0.75138122, 0.24861878],\n",
       "       [0.38624339, 0.61375661],\n",
       "       [0.42708333, 0.57291667],\n",
       "       [0.86315789, 0.13684211],\n",
       "       [0.92964824, 0.07035176],\n",
       "       [0.05699482, 0.94300518],\n",
       "       [0.82802548, 0.17197452],\n",
       "       [0.01546392, 0.98453608],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02298851, 0.97701149],\n",
       "       [0.96721311, 0.03278689],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01041667, 0.98958333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0326087 , 0.9673913 ],\n",
       "       [0.01020408, 0.98979592],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93785311, 0.06214689],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99462366, 0.00537634],\n",
       "       [0.        , 1.        ],\n",
       "       [0.38860104, 0.61139896],\n",
       "       [0.32065217, 0.67934783],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.31182796, 0.68817204],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00588235, 0.99411765],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98387097, 0.01612903],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62264151, 0.37735849],\n",
       "       [0.92344498, 0.07655502],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99526066, 0.00473934],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98888889, 0.01111111],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.06451613, 0.93548387],\n",
       "       [1.        , 0.        ],\n",
       "       [0.05154639, 0.94845361],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03278689, 0.96721311],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95808383, 0.04191617],\n",
       "       [0.79532164, 0.20467836],\n",
       "       [0.55665025, 0.44334975],\n",
       "       [0.        , 1.        ],\n",
       "       [0.18604651, 0.81395349],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93121693, 0.06878307],\n",
       "       [0.97740113, 0.02259887],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [0.        , 1.        ],\n",
       "       [0.44623656, 0.55376344],\n",
       "       [0.86363636, 0.13636364],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96923077, 0.03076923],\n",
       "       [0.        , 1.        ],\n",
       "       [0.21649485, 0.78350515],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98477157, 0.01522843],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.99441341, 0.00558659],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08379888, 0.91620112],\n",
       "       [0.98984772, 0.01015228],\n",
       "       [0.01142857, 0.98857143],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02747253, 0.97252747],\n",
       "       [1.        , 0.        ],\n",
       "       [0.79144385, 0.20855615],\n",
       "       [0.        , 1.        ],\n",
       "       [0.90804598, 0.09195402],\n",
       "       [0.98387097, 0.01612903],\n",
       "       [0.20634921, 0.79365079],\n",
       "       [0.19767442, 0.80232558],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.20338983, 0.79661017],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98969072, 0.01030928],\n",
       "       [0.        , 1.        ],\n",
       "       [0.48663102, 0.51336898],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07821229, 0.92178771],\n",
       "       [0.11176471, 0.88823529],\n",
       "       [0.99415205, 0.00584795],\n",
       "       [0.03015075, 0.96984925],\n",
       "       [1.        , 0.        ],\n",
       "       [0.40837696, 0.59162304],\n",
       "       [0.04891304, 0.95108696],\n",
       "       [0.51595745, 0.48404255],\n",
       "       [0.51898734, 0.48101266],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.59903382, 0.40096618],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.24157303, 0.75842697],\n",
       "       [0.81052632, 0.18947368],\n",
       "       [0.08717949, 0.91282051],\n",
       "       [0.99453552, 0.00546448],\n",
       "       [0.82142857, 0.17857143],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.125     , 0.875     ],\n",
       "       [0.04712042, 0.95287958],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.89150943, 0.10849057],\n",
       "       [0.1978022 , 0.8021978 ],\n",
       "       [0.95238095, 0.04761905],\n",
       "       [0.00515464, 0.99484536],\n",
       "       [0.609375  , 0.390625  ],\n",
       "       [0.07692308, 0.92307692],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.84210526, 0.15789474],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.95876289, 0.04123711],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.26903553, 0.73096447],\n",
       "       [0.98461538, 0.01538462],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00574713, 0.99425287],\n",
       "       [0.85142857, 0.14857143],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.76506024, 0.23493976],\n",
       "       [0.8969697 , 0.1030303 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.73333333, 0.26666667],\n",
       "       [0.47727273, 0.52272727],\n",
       "       [0.        , 1.        ],\n",
       "       [0.92473118, 0.07526882],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87709497, 0.12290503],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.74752475, 0.25247525],\n",
       "       [0.09146341, 0.90853659],\n",
       "       [0.44329897, 0.55670103],\n",
       "       [0.22395833, 0.77604167],\n",
       "       [0.        , 1.        ],\n",
       "       [0.87046632, 0.12953368],\n",
       "       [0.78212291, 0.21787709],\n",
       "       [0.00507614, 0.99492386],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02884615, 0.97115385],\n",
       "       [0.96571429, 0.03428571],\n",
       "       [0.93478261, 0.06521739],\n",
       "       [1.        , 0.        ],\n",
       "       [0.49756098, 0.50243902],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01604278, 0.98395722],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96987952, 0.03012048],\n",
       "       [0.        , 1.        ],\n",
       "       [0.05747126, 0.94252874],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98989899, 0.01010101],\n",
       "       [0.01675978, 0.98324022],\n",
       "       [1.        , 0.        ],\n",
       "       [0.13541667, 0.86458333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00546448, 0.99453552],\n",
       "       [0.        , 1.        ],\n",
       "       [0.41836735, 0.58163265],\n",
       "       [0.11309524, 0.88690476],\n",
       "       [0.22110553, 0.77889447],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97647059, 0.02352941],\n",
       "       [0.22826087, 0.77173913],\n",
       "       [0.98882682, 0.01117318],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96428571, 0.03571429],\n",
       "       [0.33507853, 0.66492147],\n",
       "       [0.98235294, 0.01764706],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06043956, 0.93956044],\n",
       "       [0.97619048, 0.02380952],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03108808, 0.96891192],\n",
       "       [0.57291667, 0.42708333]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Patches and Random Subspaces\n",
    "\n",
    "The `BaggingClassifier` class supports sampling the features also. This is controlled by the `max_features` and `bootstrap_features` hyperparameters. They work the same way that `max_samples` and `bootstrap` do, but for feature sampling instead of instance sampling. Thus, each predictor will be trained on a random subset of the input features.\n",
    "\n",
    "This is useful when dealing with high-dimensional inputs (like photos). Sampling both training instances and features is called [*Random Patches*](https://goo.gl/B2EcM2). Keeping all training instances (`boostrap=False` and `max_samples=1.0`) but sampling instances (`bootstrap_features=True` and/or `max_features < 1.0`) is called the [*Random Subspaces method*](https://goo.gl/NPi5vH).\n",
    "\n",
    "*Note: sampling features results in even more predictor diversity, trading a bit more bias for a lower variance*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "A Random Forest is an ensemble of decision trees, generally trained via the bagging method (or sometimes pasting), typically with `max_samples` set to the size of the training set. Instead of building a `BaggingClassifier` and passing it a `DecisionTreeClassifier`, you can use the `RandomForestClassifier` class instead (there's a similar `RandomForestRegressor` as well. The following code will train a random forest with 500 treas (each limited to 16 nodes) using all available CPU cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a few exceptions, the hyperparameters for `RandomForestClassifier` and `DecisionTreeClassifier` the same, plus the inclusion of all of the `BaggingClassifier` hyperparameters.\n",
    "\n",
    "The algo introduces extra randomness when growing trees; instead of searching for the very best feature when splitting a node, it searches for the best features among a random subset of features. This will result in greater tree diversity- which once again trades higher bias for lower variance and it will (generally) yield an overall better model. The following `BaggingClassifier` is *roughly* equivalent to the `RandomForestClassifier` from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(splitter='random', max_leaf_nodes=16),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bg = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra-Trees\n",
    "\n",
    "When a tree in the Random Forest is growing, at each node we have a random subset of the features that gets considered for splitting. It's possible to make these trees more random by also using random thresholds for each feature rather than searching for the best possible thresholds (like regular Decision Trees do).\n",
    "\n",
    "A forest of such extremely-random trees is known as an [*Extremely Randomized Tree*](https://goo.glRHGEA4). Once again, this trades more bias for lower variance. It also makes Extra-Trees much faster to train than regular Random Forests since finding the best possible threshold for each feature at every node is one of the most time consuming tasks of growing a decision tree.\n",
    "\n",
    "Sklearn has a class called `ExtraTreesClassifier`, with an identical API to the `RandomForestClassifier` class. Similarly, the `RandomForestRegressor` has the same API as the `RandomForestRegressor`.\n",
    "\n",
    "Generally, it's hard to know which will perform better so the only way to know is to try both and compare using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Another great quality of RandomForests is that they make it easy to measure relative importance of each feature. Sklearn measures a feature's importance by looing how much the tree nodes that use the feature reduce impurity on average (across all trees in the forest). More accurately, it's a weighted average where each node's weight is equal to the number of training samples that are associated with it.\n",
    "\n",
    "Sklearn does this automatically for each feature after training, then scoes the results so that the sum of all importances is equal to 1. You can access this result using `feature_importances_variable`. For example, the next bit will train a RandomForestClassifier on the iris dataset and outputs each feature's importance.\n",
    "\n",
    "Overall, Random Forests are extremely handy to get a quick understanding of what features actually matter (especially if you need to do feature selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.11249225099876374\n",
      "sepal width (cm) 0.023119288282510326\n",
      "petal length (cm) 0.44103046436395765\n",
      "petal width (cm) 0.4233579963547681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(iris['data'], iris['target'])\n",
    "\n",
    "for name, score in zip(iris['feature_names'], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "*Boosting* (originally called *hypothesis boosting* refers to any Ensemble method that can combine serveral weak learners into a strong learner. The general idea of most boosting methods is to train predictors sequentially, each trying to correct its predecessor. There are many methods available, but the most popular by far are [*AdaBoost*](https://goo.gl/OIduRW) (short for *Adaptive Boosting*) and *Gradient Boosting*. Firstly, AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "\n",
    "One way for a new predictor to correct its predecessor is to pay a bit more attention to the training instances that the predecessor underfitted. This results in new predictors focusing more and more on the hard cases. This is, in essence, the magic behind AdaBoost.\n",
    "\n",
    "To build an AdaBoost classifier, a first base classifier (like a Decision Tree) is trained and used to make predictions on the training set. The relative weight of misclassified training instances is then increased. A second classifier is trained using the updated weights and again it makes predictions on the training set, weights are updated, and so on.\n",
    "\n",
    "This sequential learning technique has some similarities with Gradient Descent, except that instead of tweaking a single predictor's parameters to minimize a cost function, AdaBoost adds predictors to the ensemble, gradually making it better.\n",
    "\n",
    "Once all predictors are trained, the ensemble makes predictions very much like bagging or pasting, except that predictors have different weights depending on their overall accuracy on the weighted training set.\n",
    "\n",
    "*Note: There's one important drawback to this technique; it cannot be parallelized (or only partially) since each predictor can only be trained after the previous predictor has been trained and evaluated. As a result, it doesn't scale as well as bagging or pasting do.*\n",
    "\n",
    "Time to take a closer look at the algorithm. Each instance weight $w^i$ is initially set to $\\frac{1}{m}$. A first predictor is trained and its weighted error rate $r_1$ is computed on the training set. Here's the equation for this section:\n",
    "\n",
    "$$r_j = \\frac{\\mathop{\\sum_{i=1}^m w^i}_{\\hat{y}_j^i \\neq y^i}}{\\sum_{i=1}^m w^i} \\text{ where $\\hat{y}_j^i$ is the $j^{th}$ predictor's prediction for the $i_{th}$ instance}.$$\n",
    "\n",
    "The predictor's weight $\\alpha_j$ is then computed using the next equation, where $\\eta$ is the learning rate hyperparameter (defaults to 1). The more accurate the predictor is, the heigher its weight will be. If it's just randomly guessing, then its weight will be close to 0. However, if it's most often wrong (i.e., less accurate then random guessing) then its weight will be negative:\n",
    "\n",
    "$$\\alpha_j = \\eta\\log\\frac{1 - r_j}{r_j}$$\n",
    "\n",
    "Next up, the instance weights are updated using the next equation; the misclassified instances are boosted.\n",
    "\n",
    "$$\\text{for } i = 1, 2, \\cdots, m\\\\ w^i \\leftarrow \\begin{align*}\\left\\{\\begin{array}{ll}w^i &\\text{if $\\hat{y}_j^i = y^i$} \\\\ w^i\\exp(\\alpha_j) &\\text{if $\\hat{y}_j^i \\neq y^i$}\\end{array}\\right.\\end{align*}$$\n",
    "\n",
    "Then, all the instances wates are normalized (so they're divided by $\\sum_{i=1}^m w^i$).\n",
    "\n",
    "Finally, a new predictor is trained using the updated weights and the whole process is repeated. The algorithm stops when the desired number of predictors is reached, or when a perfect predictor is found.\n",
    "\n",
    "For prediction making, AdaBoost simply computes the prodictions of all the predictors and weighs them using the predictor weights $\\alpha_j$. The predicted class is the one that receives the majority of weighted votes. Here's the equation:\n",
    "\n",
    "$$\\hat{y}(\\textbf{x}) = \\mathop{\\text{argmax}}_k \\mathop{\\sum_{j=1}^N}_{\\hat{y}_j(\\textbf{x}) = k} \\alpha_j \\text{ where $N$ is the number of predictors.}$$\n",
    "\n",
    "Sklearn uses as multiclass version of AdaBoost called [*SAMME*](https://goo.gl/Eji2vR) (which stands for *Stagewise Additive Modeling using a Multiclass Exponential loss function*). When there are just two classes, SAMME is equivalent to AdaBoost. Moreover, if the predictors can estimate class probabilities (i.e., if they have a `predict_proba()` method), sklearn cause use a varient of SAMME called *SAMME.R* (the *R* stands for \"Real\") which relies on class probabilities rather than predictions and generally performs better.\n",
    "\n",
    "The following code trains an AdaBoost classifier based on 200 *Decision Stumps* using sklearn's `AdaBoostClassifier` class (and there's an `AdaBoostRegressor` as well). A Decision Stump is a Decision Tree with `max_depth=1` (so a tree composed of a single decision node + two leaf nodes):\n",
    "\n",
    "*Note: if your AdaBoost ensemble is overfitting the training set, you can try reducing the number of estimators or more strongly regularizing the base estimator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm='SAMME.R', learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "Another popular boosting algorithm is [*Gradient Boosting*](https://goo.gl/Ezw4jL). Just like AdaBoost, Gradient Boosting works by sequentially adding predictors to an ensemble, each one correccting its predecessor. However, instead of tweaking the instance weights at every iteration like AdaBoost does, this method tries to fit the new predictor to the *residual errors* made by the previous predictor.\n",
    "\n",
    "Let's go through a simple regression example using Decision Trees as the base predictors. This is called *Gradient Tree Boosting* or *Gradient Boosted Regression Trees* (*GBRT*). First, let's fit a `DecisionTreeRegressor` to the training set (for example, a noisy quadratic training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train a second `DecisionTreeRegressor` on the residual errors made by the first predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it again, but on the residual errors made by the second predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our 3 tree ensemble can make predictions on a new instance  by summing the predictions of all of the trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[0.8]])\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x792 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here are some nice graphs to see visuals of what we've done\n",
    "def plot_predictions(regressors, X, y, axes, label=None, style=\"r-\", data_style=\"b.\", data_label=None):\n",
    "    x1 = np.linspace(axes[0], axes[1], 500)\n",
    "    y_pred = sum(regressor.predict(x1.reshape(-1, 1)) for regressor in regressors)\n",
    "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
    "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
    "    if label or data_label:\n",
    "        plt.legend(loc=\"upper center\", fontsize=16)\n",
    "    plt.axis(axes)\n",
    "\n",
    "plt.figure(figsize=(11,11))\n",
    "\n",
    "plt.subplot(321)\n",
    "plot_predictions([tree_reg1], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h_1(x_1)$\", style=\"g-\", data_label=\"Training set\")\n",
    "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
    "plt.title(\"Residuals and tree predictions\", fontsize=16)\n",
    "\n",
    "plt.subplot(322)\n",
    "plot_predictions([tree_reg1], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h(x_1) = h_1(x_1)$\", data_label=\"Training set\")\n",
    "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
    "plt.title(\"Ensemble predictions\", fontsize=16)\n",
    "\n",
    "plt.subplot(323)\n",
    "plot_predictions([tree_reg2], X, y2, axes=[-0.5, 0.5, -0.5, 0.5], label=\"$h_2(x_1)$\", style=\"g-\", data_style=\"k+\", data_label=\"Residuals\")\n",
    "plt.ylabel(\"$y - h_1(x_1)$\", fontsize=16)\n",
    "\n",
    "plt.subplot(324)\n",
    "plot_predictions([tree_reg1, tree_reg2], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h(x_1) = h_1(x_1) + h_2(x_1)$\")\n",
    "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
    "\n",
    "plt.subplot(325)\n",
    "plot_predictions([tree_reg3], X, y3, axes=[-0.5, 0.5, -0.5, 0.5], label=\"$h_3(x_1)$\", style=\"g-\", data_style=\"k+\")\n",
    "plt.ylabel(\"$y - h_1(x_1) - h_2(x_1)$\", fontsize=16)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "\n",
    "plt.subplot(326)\n",
    "plot_predictions([tree_reg1, tree_reg2, tree_reg3], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h(x_1) = h_1(x_1) + h_2(x_1) + h_3(x_1)$\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simpler way to train GBRT ensembles is to use sklearn's `GradientBoostingRegressor` class. Much like the `RandomForestRegressor`, it has hyperparameters to control the growth of Decision Trees (e.g., `max_depth`, `min_samples_leaf`, and so on) as well as hyperparams to control the ensemble training, such as the number of trees (`n_estimators`). The `learning_rate` hyperparam scales the contribution of each tree. If set to a low value (such as 0.1), more trees in the ensemble will be needed to fit the training set (but the predictions will usually generalize better). This is a regularization technique known as *shrinkage*. The following code creates the same ensemble as the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=1.0, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=3, presort='auto', random_state=42,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the optimal number of trees, you can use early stopping (from Chapter 4). A simple way to implement this is to used the `staged_predict()` method; it returns an iterator over the predictions made by the ensemble at each stage of training (with one tree, two trees, etc). The following code trains a GBRT ensemble with 120 trees, then measures the validation error at each stage of training to find the optimal number of trees, then finally trains another GBRT ensemble using the optimal number of trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120, random_state=42)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors)\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators, random_state=42)\n",
    "gbrt_best.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbrt_best.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nice little graph for the visual learners\n",
    "\n",
    "min_error = np.min(errors)\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(errors, \"b.-\")\n",
    "plt.plot([bst_n_estimators, bst_n_estimators], [0, min_error], \"k--\")\n",
    "plt.plot([0, 120], [min_error, min_error], \"k--\")\n",
    "plt.plot(bst_n_estimators, min_error, \"ko\")\n",
    "plt.text(bst_n_estimators, min_error*1.2, \"Minimum\", ha=\"center\", fontsize=14)\n",
    "plt.axis([0, 120, 0, 0.01])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.title(\"Validation error\", fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_predictions([gbrt_best], X, y, axes=[-0.5, 0.5, -0.1, 0.8])\n",
    "plt.title(\"Best model (%d trees)\" % bst_n_estimators, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to implement early stopping by actually stopping training early (instead of training a large number of trees first and then looking back to find the optimal number). This can be done by setting `warm_start=True` which makes sklearn keep existing trees when the `fit()` method is called, allowing incremental training. The following code stops training when the validation error doesn't improve for five iterations in a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping...\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True, random_state=42)\n",
    "\n",
    "min_val_error = float('inf')\n",
    "error_going_up = 0\n",
    "\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            print('Stopping...')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "print(gbrt.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation MSE: 0.0026930464329994377\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum validation MSE: {}\".format(min_val_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GradientBoostingRegressor` class also supports a `subsample` hyperparam, which specifies the fraction of training instances to be used for training each tree. For example, if `subsample=0.25`, then each tree is trained on 25% of the training instances, selected randomly. As you can probably guess, this trades a higher bias for a lower variance. It also speeds up training considerably. This technique is known as *Stochastic Gradient Boosting*.\n",
    "\n",
    "*Note: it's possible to use Gradient Boosting with other cost functions. This is controlled by the `loss` hyperparameter. See the documentation for more details.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "The last ensemble method for this chapter is known as [*stacking*](https://goo.gl/9I2NBw) (short for *stacked generalization*). It's based on a simple idea; instead of using trivial functions (like hard voting) to aggregate the predictions of all predictions in an ensemble, why don't we just train a model to do this aggregation? For this, a final predictor (known as a *blender* or *meta learner*) takes the predictions from the input models and makes a final predictor.\n",
    "\n",
    "For blender training, a common approach is to use a hold-out set (though out-of-fold pedictions is also possible). First, the training set is split into two subsets. The first subset is used to train the predictors in the first layer. Next, the first layer predictors are used to make predictions on the second (held-out) set. Now for each instance in the hold-out set, there are three predicted valuse that can be used to create a new training set. The blender is trained on this new set, so it learns to predict the target value given the first layer's predictions.\n",
    "\n",
    "It's possible to train several different blenders this way (e.g., one using Linear Regression, one using Random Forest Regression, and so on); we get a whole layer of blenders. The trick is to split the training set into three subsets. The first one is used to train the first layer, the second one is used to create the training set used to train the second layer (using predictions made by the predictors of the first layer) and the third is used to create the training set to train the third layer (using the predictions made by the predictors of the second layer). Once this is done, we can make a prediction fot a new instance by going through each layer sequentially.\n",
    "\n",
    "This kind of sounds like a neural network, and in a way it kind of is.\n",
    "\n",
    "Sadly, sklearn doesn't stupport stacking directly, but it's not that bad to implement (as we'll see shortly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.76 s, sys: 2.38 s, total: 4.13 s\n",
      "Wall time: 29.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "home = expanduser(\"~/Coding Stuff/Python/handson-ml/datasets/\")\n",
    "\n",
    "# If we have the data, remove it first\n",
    "find_and_remove('mnist-original.mat')\n",
    "\n",
    "# Download the data\n",
    "mnist = fetch_mldata(\"MNIST original\", target_name='target', data_home=home)\n",
    "\n",
    "# split our data\n",
    "\n",
    "# Split into test data and train/validation data\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(mnist.data, mnist.target, test_size=10000, random_state=42)\n",
    "\n",
    "# Now split into train data and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifiers\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# First up, RandomForest\n",
    "random_forest_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Next, ExtraTrees\n",
    "extra_trees_clf = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_clf = LinearSVC(random_state=42)\n",
    "\n",
    "# Last, a neural network (!!)\n",
    "mlp_clf = MLPClassifier(random_state=42)\n",
    "\n",
    "# populate a list of our classifiers\n",
    "estimators = [random_forest_clf, extra_trees_clf, svm_clf, mlp_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Training the ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "Training the LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0)\n",
      "Training the MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9467, 0.9512, 0.8547, 0.9542]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train classifiers (could take a while)\n",
    "for estimator in estimators:\n",
    "    print(\"Training the {}\".format(estimator))\n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "# Get scores from validation set\n",
    "[estimator.score(X_val, y_val) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVM gets pretty wrecked by the other classifiers... for now. But we'll keep it around for the voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_estimators = [\n",
    "    ('random_forest_clf', random_forest_clf),\n",
    "    ('extra_trees_clf', extra_trees_clf),\n",
    "    ('svm_clf', svm_clf),\n",
    "    ('mlp_clf', mlp_clf)\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(named_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "   ...       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train our VotingClassifier (again may take a while because of SVM)\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9467, 0.9512, 0.8547, 0.9542]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scores from validation set\n",
    "[estimator.score(X_val, y_val) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('random_forest_clf',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=42, verbose=0, warm_start=False)),\n",
       " ('extra_trees_clf',\n",
       "  ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False)),\n",
       " ('svm_clf', None),\n",
       " ('mlp_clf',\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "         beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "         hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "         learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "         nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "         solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "         warm_start=False))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remove the SVM and see if it's better\n",
    "voting_clf.set_params(svm_clf=None)\n",
    "\n",
    "# This updated the list of estimators\n",
    "voting_clf.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "      verbose=0),\n",
       " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "        solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "        warm_start=False)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But the list of TRAINED estimators is the same\n",
    "voting_clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9654"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can either retrain, or just delete the SVM\n",
    "\n",
    "del voting_clf.estimators_[2]\n",
    "\n",
    "# Re-evaluate the voting classifier\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9683"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better! The SVM was messing things up. Now, we'll use a soft voting classifier\n",
    "# retraining isn't necessary since we can change the voting hyperparameter to 'soft'\n",
    "\n",
    "voting_clf.voting = 'soft'\n",
    "\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.965"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So far, this one is the best one. Let's check it against the test set and each classifier on the test set\n",
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9434, 0.9444, 0.9524]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_test, y_test) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting classifier reduced the error rate from about 4.9% for our best model (the `MLPClassifier`) to just 3.5%. That's about 28% less errors, not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) DIY Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_predictions = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 2., 2.],\n",
       "       [7., 7., 7., 7.],\n",
       "       [4., 4., 4., 4.],\n",
       "       ...,\n",
       "       [4., 4., 4., 4.],\n",
       "       [9., 9., 9., 9.],\n",
       "       [4., 4., 4., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=True, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForest blender and train it on the predictions\n",
    "\n",
    "rnd_forest_blender = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n",
    "rnd_forest_blender.fit(X_val_predictions, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9613"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try other kinds of blenders. Perhaps a neural network blender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_predictions = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_blender = MLPClassifier(random_state=42)\n",
    "mlp_blender.fit(X_val_predictions, y_val)\n",
    "\n",
    "y_pred = mlp_blender.predict(X_val_predictions)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our Neural Network blender is actually worse than the RandomForestClassifier. We'll rock with the RandomForest one for now then. How bout some Grid Search for finding the best hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      "[CV] max_depth=1, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=6 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=1, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=6 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=6 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=8 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=8 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=1, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=8 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=1, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=10 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=11 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=11 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=11 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=12 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=12, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=12 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=12, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=12 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=12, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=14 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=14, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=14 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=14, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=14 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=14, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=15 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=15, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=15 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=15, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=15 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=15, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=16 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=16, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=16 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=16, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=16 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=16, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=17 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=17, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=17 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=17, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=17 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=17, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=18 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=18, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=18 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=18, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=18 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=18, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=19 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=19 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=19 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=20 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=20, total=   0.0s\n",
      "[CV] max_depth=1, n_estimators=21 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=21 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=21 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=40 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=40 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=40 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=41 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=41 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=41 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=42, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=42, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=42, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=45, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=45, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=45, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=48, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=48, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=48, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=49, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=49, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=49, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=50, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=50, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=50, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=51, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=51, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=51, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=52, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=52, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=52, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=53, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=53, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=53, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=54, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=54, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=54, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=55, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=55, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=55, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=56, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=56, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=56, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=57, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=57, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=57, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=58, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=58, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=58, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=60 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=60, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=60 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=60 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=61, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=62, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=62, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=62, total=   0.1s\n",
      "[CV] max_depth=1, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=66, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=69, total=   0.5s\n",
      "[CV] max_depth=1, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=69, total=   0.5s\n",
      "[CV] max_depth=1, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=69, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=71, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=72, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=72, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=72, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=73, total=   0.4s\n",
      "[CV] max_depth=1, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=74, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=75, total=   0.4s\n",
      "[CV] max_depth=1, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=76, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=76, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=76, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=77, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=77, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=77, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=78, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=78, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=78, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=79 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=79 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=79 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=80, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=80, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=80, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=81, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=81, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=81, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=82, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=82, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=82, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=83, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=83, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=83, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=84, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=84, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=84, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=85, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=85, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=85, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=86, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=86, total=   0.4s\n",
      "[CV] max_depth=1, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=86, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=89, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=89, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=89, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=90, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=90, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=90, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=91, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=91, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=91, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=92, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=92, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=92, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=93, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=93, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=93, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=94, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=94, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=94, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=95, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=95, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=95, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=96, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=96, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=96, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=97, total=   0.2s\n",
      "[CV] max_depth=1, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=97, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=97, total=   0.5s\n",
      "[CV] max_depth=1, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=98, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=98, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=98, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=99 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=99, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=99 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=99, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=99 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=99, total=   0.4s\n",
      "[CV] max_depth=1, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=1, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=1, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=1, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=1, n_estimators=100, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=6 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=2, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=6 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=6 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=8 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=8 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=2, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=8 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=2, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=10 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=11 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=11 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=11 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=12 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=12, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=12 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=12, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=12 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=12, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=14 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=14, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=14 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=14, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=14 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=14, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=15 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=15, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=15 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=15, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=15 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=15, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=16 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=16, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=16 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=16, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=16 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=16, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=17 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=17, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=17 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=17, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=17 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=17, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=18 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=18, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=18 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=18, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=18 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=18, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=19 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=19, total=   0.0s\n",
      "[CV] max_depth=2, n_estimators=19 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=19 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=21 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=21 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=21 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=40 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=40 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=40 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=41 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=41 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=41 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=42, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=42, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=42, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=45, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=45, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=45, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=48, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=48, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=48, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=49, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=49, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=49, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=50, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=50, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=50, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=51, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=51, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=51, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=52, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=52, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=52, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=53, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=53, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=53, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=54, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=54, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=54, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=55, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=55, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=55, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=56, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=56, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=56, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=57, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=57, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=57, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=58, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=58, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=58, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=59, total=   0.1s\n",
      "[CV] max_depth=2, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=60 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=60 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=60 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=62, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=62, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=62, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=69, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=69, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=69, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=72, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=72, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=72, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=76, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=76, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=76, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=77, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=77, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=77, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=78, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=78, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=78, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=79 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=79 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=79 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=80, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=80, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=80, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=81, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=81, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=81, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=82, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=82, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=82, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=83, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=83, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=83, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=84, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=84, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=84, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=85, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=85, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=85, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=86, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=86, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=86, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=89, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=89, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=89, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=90, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=90, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=90, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=91, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=91, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=91, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=92, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=92, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=92, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=93, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=93, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=93, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=94, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=94, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=94, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=95, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=95, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=95, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=96, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=96, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=96, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=97, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=97, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=97, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=98, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=98, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=98, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=99 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=2, n_estimators=99, total=   0.2s\n",
      "[CV] max_depth=2, n_estimators=99 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=99, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=99 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=99, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=5 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=3, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=6 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=6 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=6 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=7 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=3, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=8 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=8 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=8 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=3, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=9 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=3, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=11 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=11 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=11 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=12 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=12, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=12 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=12, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=12 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=12, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=14 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=14, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=14 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=14, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=14 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=14, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=15 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=15, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=15 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=15, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=15 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=15, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=16 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=16, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=16 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=16, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=16 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=16, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=17 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=17, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=17 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=17, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=17 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=17, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=18 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=18, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=18 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=18, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=18 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=18, total=   0.0s\n",
      "[CV] max_depth=3, n_estimators=19 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=19 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=19 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=21 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=21 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=21 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=22 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=40 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=40 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=40 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=41 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=41 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=41 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=42, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=42, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=42, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=45, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=45, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=45, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=48, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=48, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=48, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=49, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=49, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=49, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=50, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=50, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=50, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=51, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=51, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=51, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=52, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=52, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=52, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=53, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=53, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=53, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=54, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=54, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=54, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=55, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=55, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=55, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=56, total=   0.1s\n",
      "[CV] max_depth=3, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=56, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=56, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=57, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=57, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=57, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=58, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=58, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=58, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=60 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=60 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=60 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=61 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=62, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=62, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=62, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=68, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=69, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=69, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=69, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=72, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=72, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=72, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=76, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=76, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=76, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=77, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=77, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=77, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=78, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=78, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=78, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=79 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=79 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=79 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=80, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=80 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=80, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=80, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=81, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=81, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=81, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=82, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=82, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=82, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=83, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=83, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=83, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=84, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=84, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=84, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=85, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=85, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=85, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=86, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=86, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=86, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=89, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=89, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=89, total=   0.2s\n",
      "[CV] max_depth=3, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=90, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=90, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=90, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=91, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=91, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=91, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=92, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=92, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=92, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=93, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=93, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=93, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=94, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=94, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=94, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=95, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=95, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=95, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=96, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=96, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=96, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=97, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=97, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=97, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=98, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=98, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=98, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=99 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=99, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=99 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=99, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=99 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=3, n_estimators=99, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=1 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=1, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=2 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=2, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=3 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=3, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=4 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=4, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=5 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=4, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=5 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=5, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=6 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=6 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=6 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=6, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=7 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=7, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=8 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=4, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=8 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=8 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=8, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=9 .....................................\n",
      "[CV] ...................... max_depth=4, n_estimators=9, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=10 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=10 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=10, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=11 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=11 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=11 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=11, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=12 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=12, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=12 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=12, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=12 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=12, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=13 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=13 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=13, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=14 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=14, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=14 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=14, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=14 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=14, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=15 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=15, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=15 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=15, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=15 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=15, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=16 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=16, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=16 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=16, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=16 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=16, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=17 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=17, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=17 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=17, total=   0.0s\n",
      "[CV] max_depth=4, n_estimators=17 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=17, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=18 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=18, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=18 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=18, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=18 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=18, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=19 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=19 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=19 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=19, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=20 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=20, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=21 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=21 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=21 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=21, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=22 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=22, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=23 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=23, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=24 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=24, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=25 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=25, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=26 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=26, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=27 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=27, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=28 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=28, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=29 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=29, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=30 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=30, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=31 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=31, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=32 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=32, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=33 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=33, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=34 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=34, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=35 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=35, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=36 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=36, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=37 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=37, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=38 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=38, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=39 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=39, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=40 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=40 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=40 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=40, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=41 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=41, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=41 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=41 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=41, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=42, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=42, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=42 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=42, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=43 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=43, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=44 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=44, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=45, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=45, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=45 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=45, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=46 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=46, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=47, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=47 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=47, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=48, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=48, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=48 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=48, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=49, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=49, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=49 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=49, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=50, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=50, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=50, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=51, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=51, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=51 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=51, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=52, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=52, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=52 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=52, total=   0.1s\n",
      "[CV] max_depth=4, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=53, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=53, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=53 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=53, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=54, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=54, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=54 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=54, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=55, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=55, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=55 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=55, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=56, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=56, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=56 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=56, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=57, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=57, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=57 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=57, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=58, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=58, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=58 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=58, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=59 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=59, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=60 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=60 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=60 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=60, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=61 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=61, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=62, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=62, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=62 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=62, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=63 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=63, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=64 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=64, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=65 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=65, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=66 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=66, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=67 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=67, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=68 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=68, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=69, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=69, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=69 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=69, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=70, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=70 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=70, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=71 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=71, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=72, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=72, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=72 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=72, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=73 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=73, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=74 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=74, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=75 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=75, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=76, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=76, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=76 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=76, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=77, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=77, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=77 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=77, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=78, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=78, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=78 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=78, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=79 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=79 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=79 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=79, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=80, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=80, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=80 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=80, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=81, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=81, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=81 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=81, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=82, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=82, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=82 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=82, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=83, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=83, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=83 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=83, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=84, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=84, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=84 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=84, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=85, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=85, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=85 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=85, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=86, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=86, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=86 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=86, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=87, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=87 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=87, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=88, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=88 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=88, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=89, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=89, total=   0.2s\n",
      "[CV] max_depth=4, n_estimators=89 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=89, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=90, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=90, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=90 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=90, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=91, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=91, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=91 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=91, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=92, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=92, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=92 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=92, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=93, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=93, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=93 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=93, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=94, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=94, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=94 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=94, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=95, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=95, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=95 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=95, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=96, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=96, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=96 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=96, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=97, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=97, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=97 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=97, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=98, total=   0.4s\n",
      "[CV] max_depth=4, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=98, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=98 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=98, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=99 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=4, n_estimators=99, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=99 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=99, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=99 ....................................\n",
      "[CV] ..................... max_depth=4, n_estimators=99, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=100, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1200 out of 1200 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=True, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100], 'max_depth': [1, 2, 3, 4]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_val_predictions = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)\n",
    "    \n",
    "param_grid = [\n",
    "    {'n_estimators': list(range(1, 101)), 'max_depth': list(range(1, 5))},\n",
    "]\n",
    "best_blender = GridSearchCV(rnd_forest_blender, param_grid, cv=3, verbose=2)\n",
    "best_blender.fit(X_val_predictions, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=43, n_jobs=1,\n",
       "            oob_score=True, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_blender.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9517"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "    \n",
    "y_pred = best_blender.best_estimator_.predict(X_test_predictions)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare it to our original rnd_forest_blender\n",
    "\n",
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "    \n",
    "y_pred = rnd_forest_blender.predict(X_test_predictions)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite as good as our soft voting classifier, but still better than any model on its own. The Grid Search and our own blender are basically identical in their predictions, so, that's pretty cool to see."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
