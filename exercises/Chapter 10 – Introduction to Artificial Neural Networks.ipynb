{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Artificial Neural Networks\n",
    "\n",
    "*Artificial Neural Networks* (ANNs) are inspired by the architecture of the brain. ANNs are at the core of Deep Learning. They're versatile, powerful, and scalable, making them ideal to tackle large and highly complex ML tasks such as classifying billions of images (e.g. Google Images), powering speech recognition services (e.g. Siri, Cortana, etc), recommending the best videso to watch to hundreds of millions of users daily (e.g. the YouTube algorithm), or learning to beat the world champion at the game of *Go* by examining millions of paast games and then playing against istelf (DeepMind's AlphaGo).\n",
    "\n",
    "This chapter will introduce ANNs, starting with a quick tour of the first ANN architectures. We'll then present *Multi-Layer Perceptrons* (MLPs) and implement one using TensorFlow to tackle the MNIST digit classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Biological to Artificial Neurons\n",
    "\n",
    "ANNs are surprisingly old; they were first introduced in 1943 by the neurophysiologist Warren McCulloch and the mathematician Walter Pitts in their landmark paper [\"A Logical Calculus of Ideas Immanent in Nervous Activity\"](https://goo.gl/Ul4mxW). They presented a simplified computational model of how biological neurons may work together in animal brains to perform complex computations using *propositional logic*. This was the first ANN architecture, and since then many others have been invented.\n",
    "\n",
    "The early successes of ANNS till the 60s led to the belief that truly intelligent machines would exist. The funding went elsewhere when people realized that that dream wouldn't be feasible, but in the early 80s there was a revival of interest in ANNs as the new network architectures were invented and better training techniques were developed. By the 90s, powerful alternative ML techniques such as SVMs were favored by most researchers as they seemed to offer better results and stronger theoretical foundations.\n",
    "\n",
    "We're in another ANN renaissance, but this one may last because:\n",
    "\n",
    "* There's a __huge__ quantity of data available to train neural networks, and ANNs frequently outperform other ML techniques on very large and complex problems.\n",
    "\n",
    "* The tremendous increase in computing power since the 90s now makes it possible to train large neural nets in a reasonable amount of time. This is partially due to Moore's Law, but also due to powerful GPUs being developed by the gaming industry.\n",
    "\n",
    "* The training algos have improved. They're really only slightly different than the ones from the 90s, but those tweaks have a huge positive impact.\n",
    "\n",
    "* Some theoretical limits of ANNs have turned out to be benign in practice. (One example is how people thought that training algos would get stuck at local optima but that's rather rare in practice).\n",
    "\n",
    "* ANNs seem to have entered a virtuous circle of funding and progress. Amazing products based on ANNs regularly make the headline news, which pulls more attention and funding towards them, resulting in more progress and products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Perceptron\n",
    "\n",
    "*Perceptrons* are one of the simplest ANN architectures. They were invented in 1957 by Frank Rosenblatt (yup, that guy). It's blased on an artificial neuron known as a *Linear Threshold Unit* (LTU); the inputs and outputs are numbers and each input connection is associated with a weight. The LTU computes a weighted sum of the inputs ($z = w_1x_1 + w_2x_2 + \\cdots + w_nx_n = \\textbf{w}^T \\cdot \\textbf{x}$), then applies a *step function* to that sum and outputs the result: $h_w(\\textbf{x}) = \\text{step}(z) = \\text{step}(\\textbf{w}^T \\cdot \\textbf{x})$\n",
    "\n",
    "The most common step function used in Perceptrons is the *Heaviside step function* given in the next equation:\n",
    "\n",
    "$$\\text{heaviside }(z) = \\left\\{\\begin{array}{ll} 0 &\\text{ if } z \\lt 0 \\\\ 1 &\\text{ if } z \\geq 0\\end{array}\\right.$$\n",
    "\n",
    "Another common function is the *sign function* given below:\n",
    "\n",
    "$$\\text{sgn }(z) = \\left\\{\\begin{array}{ll} -1 &\\text{ if } z \\lt 0 \\\\ 0 &\\text{ if } z = 0 \\\\ 1 &\\text{ if } z \\gt 0\\end{array}\\right.$$\n",
    "\n",
    "A single LTU can be used for simple linear binary calssification. It computes a linear combination of the inputs and if the result exceeds a threshold, it outputs the positive class (else outputs the negative class). This works like a Logistic Regression classifier or a Linear SVM. You could use a single LTU to classify iris flowers based on petal length and width (with an extra bias feature $x_0 = 1$ like in the previous chapters). Training an LTU means finding the right values for $w_0, w_1, \\text{ and } w_2$.\n",
    "\n",
    "A Perceptron is a single layer of LTUs with each neuron connected to all of the inputs. These connections are often represented using special pass-through neurons called *input neurons*; they just output whatever input they're fed. Moreover, an extra bias feature is generally added ($x_0 = 1$). This bias feature is typically represented using a special type of neuron called a *bias neuron*, which just outputs 1 all of the time.\n",
    "\n",
    "The first training algo for Perceptrons (proposed by Rosenblatt) was largely inspired by *Hebb's rule*. In his book *The Organization of Behavior*, Hebb suggested that when a biologial neuron triggers another neuron, the connection between these two neurons grows stronger. This rule became known as *Hebbian learning*; that is, the connection weight between two neurons is increased whenever they have the same output. Perceptrons are trained using a variant of this rule that accounts for the error made by the network (it doesn't reinforce connections that lead to the wrong output). The equation is given below:\n",
    "\n",
    "$$w_{i, j}^{(\\text{next step})} = w_{i, j} + \\eta\\Big(y_j - \\hat{y}_j\\Big)x_i$$\n",
    "\n",
    "* $w_{i, j}$ is the connection weight between the i<sup>th</sup> input neuron and the j<sup>th</sup> output nuron.\n",
    "* $x_i$ is the i<sup>th</sup> input value of the current training instance.\n",
    "* $\\hat{y}_j$ is the output of the j<sup>th</sup> output neuron for the current training instance.\n",
    "* $y_i$ is the target output of the j<sup>th</sup> output neuron for the current training instance.\n",
    "* $\\eta$ is the learning rate.\n",
    "\n",
    "The decision boundary of each output neron is linear, so Perceptrons are incapable of learning complex patters (just like Logistic Regression classifiers). However, if the traiing instanes are linearly separable, Rosenblatt demonstrated that this algo will converge to a solution. This is called the *Perceptron convergence theorem*.\n",
    "\n",
    "Scikit-Learn provides a `Perceptron` class that implements a single LTU network. It can be used exactly as expected (here using the iris dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) # Iris-Setosa?\n",
    "\n",
    "per_clf = Perceptron(random_state=42, max_iter=100)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptrons strongly resemble Stochastic Gradient Descent, and sklearn's `Perceptron` class is equivalent to the `SGDClassifier` class with the following hyperparams: `loss='perceptron'`, `learning_rate='constant'`, `eta0=1` (learning rate), and `penalty=None` (no regularization).\n",
    "\n",
    "Contrary to logistic regression classifiers, Perceptrons don't output a class probability; rather, they make predictions based on a hard threshold. This is one of the good reasons to prefer Logistic Regression over Perceptrons.\n",
    "\n",
    "Many of the limits of Perceptrons (like that they can't solve some trivial problems) are eliminated by stacking multiple Perceptrons. The resulting ANN is known as a *Multi-Layer Perceptron* (MLP). An MLP is capable of solving the XOR problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron and Backpropagation\n",
    "\n",
    "An MLP is composed of one (passthrough) input layer, one or more layers of LTUs called *hidden layers*, and one final layer of LTUs called the *output layer*. Every layer except the output layer includes a bias neuron and is fully connected to the next layer. When an ANN has two or more hidden layers, it is called a *deep neural network* (DNN).\n",
    "\n",
    "Researchers struggled to find a way to train MLPs without success for years, but in 1986, D.E. Rumelhart et al. published a [groundbreaking article](https://goo.gl/Wl7Xyc) introducing *backpropagation* (we know it today as Gradient Descent using reverse-mode autodiff; Gradient Descent was introduced in chapter 4 and autodiff was introduced in chapter 9)\n",
    "\n",
    "For each training instance, the algo feeds it to the network and computes the output of each neuron in each consecutive layer (this is the forward pass). It then measures the network's output error (i.e. the difference between the desired output and the actual output of the network) and it computes how much each neuron in the last hidden layer contributed to each output neuron's error. It then proceeds to measure how much of these error contributions came from each neuron in the previous hidden layer–and so on until the algo reaches the input layer. This revese pass efficiently measures the error gradient across all the connection weights in the network by propagating the error gradient backward in the network (hence the name).\n",
    "\n",
    "If you check out the reverse-mode autodiff algo in the book in Appendix D, you'll find that the forward and reverse passses of backprop simply perform this autodiff. The last step of backprop is a Gradient Descent step on all the connection weights in the network using the error gradients measured earlier.\n",
    "\n",
    "In order for this algo to work, the authors made a key change to the MLP architecture: they replaced the step function with the logistic function $\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$ This was essential because the step function contains only flat segments (so there isn't a gradient) while the logistic function has a well-defined, nonzero derivative everywhere. The backprop algo can be used with other *activiation functions* instead of the logistic function. Two other popular ones include:\n",
    "\n",
    "* *The hyperbolic tangent function $tanh(z) = 2\\sigma(2z) - 1$*\n",
    "\n",
    "Just like the logistic function, it's S-shaped, continuous, and differentiable, but its output value ranges from -1 to 1 (instead of 0 to 1 like in logistic function) which tends to make each layer's output more or less normalized (i.e. centered around 0) at the beginning of training. This often helps speed up convergence.\n",
    "   \n",
    "* *The ReLU function (introduced in Chapter 9)*\n",
    "\n",
    "$\\text{ReLU}(z) = \\text{ max }(0, z)$ is continuous but unfortunately not differentiable at $z = 0$ (the slope changes abruptly, which can make Gradient Descent bounce around). It works very well in practice and has the advantage of being fast to compute. Most importatly, the fact that it doesn't have a maximum output value also helps reduce some issues during Gradient Descent (we'll revisit this in the next chapter)\n",
    "\n",
    "An MLP is often used for classification, with each output corresponding to a different binary class. When the classes are exclusive (like digits 0-9), the output layer is typically modified by replacing the individual activiation functions by a shared *softmax* function. The softmax function was introduced back in Chapter 4. The output of each neuron then corresponds to the estimated probability of the corresponding class. Signal only flows one-way, making this architecture an example of a *feedforward neural network* (FNN).\n",
    "\n",
    "*Note: biological neurons seem to implement a roughly sigmoid (S-shaped) activation function, so researchers stuck to sigmoid functions for a very long time. Turns out that the ReLU activation function generally works better in ANNs though.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an MLP with TensorFlow's High-Level API\n",
    "\n",
    "The simplest way to train an MLP with TensorFlow is to use the high-level API tf.learn, which offers a sklearn-compatible API. The `DNNClassifier` class makes it fairly easy to train a deep neural network with any number of hidden layers and a softmax output layer to output estimated class probabilities. For example, the following code trains a DNN for classification with two hidden layers (one with 300 neurons, one with 100) and a softmax output layer with 10 neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# First, separate the data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/pz/0k_47k855d194vh0354xcvrc0000gn/T/tmpuuj_bihh\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/pz/0k_47k855d194vh0354xcvrc0000gn/T/tmpuuj_bihh', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11b473390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/pz/0k_47k855d194vh0354xcvrc0000gn/T/tmpuuj_bihh/model.ckpt.\n",
      "INFO:tensorflow:loss = 119.14441, step = 1\n",
      "INFO:tensorflow:global_step/sec: 356.191\n",
      "INFO:tensorflow:loss = 15.699086, step = 101 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.556\n",
      "INFO:tensorflow:loss = 14.822137, step = 201 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.627\n",
      "INFO:tensorflow:loss = 6.8859353, step = 301 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.021\n",
      "INFO:tensorflow:loss = 6.187214, step = 401 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.704\n",
      "INFO:tensorflow:loss = 15.302657, step = 501 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.038\n",
      "INFO:tensorflow:loss = 3.4349823, step = 601 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.814\n",
      "INFO:tensorflow:loss = 2.40095, step = 701 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.466\n",
      "INFO:tensorflow:loss = 2.3650517, step = 801 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.007\n",
      "INFO:tensorflow:loss = 7.3984528, step = 901 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.435\n",
      "INFO:tensorflow:loss = 6.313087, step = 1001 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.836\n",
      "INFO:tensorflow:loss = 10.930757, step = 1101 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.782\n",
      "INFO:tensorflow:loss = 1.0128276, step = 1201 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.108\n",
      "INFO:tensorflow:loss = 1.50117, step = 1301 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.865\n",
      "INFO:tensorflow:loss = 11.11489, step = 1401 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.962\n",
      "INFO:tensorflow:loss = 0.4660487, step = 1501 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.24\n",
      "INFO:tensorflow:loss = 4.8908076, step = 1601 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.317\n",
      "INFO:tensorflow:loss = 8.170196, step = 1701 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.605\n",
      "INFO:tensorflow:loss = 2.7036455, step = 1801 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.704\n",
      "INFO:tensorflow:loss = 1.6300918, step = 1901 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.379\n",
      "INFO:tensorflow:loss = 5.7938967, step = 2001 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.206\n",
      "INFO:tensorflow:loss = 4.4628067, step = 2101 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.175\n",
      "INFO:tensorflow:loss = 9.993743, step = 2201 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.402\n",
      "INFO:tensorflow:loss = 0.5230455, step = 2301 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.644\n",
      "INFO:tensorflow:loss = 3.7252893, step = 2401 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.019\n",
      "INFO:tensorflow:loss = 2.8010657, step = 2501 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.831\n",
      "INFO:tensorflow:loss = 5.559836, step = 2601 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.131\n",
      "INFO:tensorflow:loss = 1.6610188, step = 2701 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.987\n",
      "INFO:tensorflow:loss = 1.6419941, step = 2801 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.162\n",
      "INFO:tensorflow:loss = 6.9222937, step = 2901 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.746\n",
      "INFO:tensorflow:loss = 5.621613, step = 3001 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.778\n",
      "INFO:tensorflow:loss = 1.321014, step = 3101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.131\n",
      "INFO:tensorflow:loss = 4.3692026, step = 3201 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.628\n",
      "INFO:tensorflow:loss = 4.070025, step = 3301 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.562\n",
      "INFO:tensorflow:loss = 1.3355005, step = 3401 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.639\n",
      "INFO:tensorflow:loss = 0.41897523, step = 3501 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.074\n",
      "INFO:tensorflow:loss = 3.154156, step = 3601 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.084\n",
      "INFO:tensorflow:loss = 2.7041965, step = 3701 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.563\n",
      "INFO:tensorflow:loss = 2.2773743, step = 3801 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.998\n",
      "INFO:tensorflow:loss = 1.0285302, step = 3901 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.178\n",
      "INFO:tensorflow:loss = 1.578288, step = 4001 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.37\n",
      "INFO:tensorflow:loss = 2.4486287, step = 4101 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.645\n",
      "INFO:tensorflow:loss = 2.1984282, step = 4201 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.84\n",
      "INFO:tensorflow:loss = 1.6631845, step = 4301 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.952\n",
      "INFO:tensorflow:loss = 0.6951519, step = 4401 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.958\n",
      "INFO:tensorflow:loss = 4.361104, step = 4501 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.583\n",
      "INFO:tensorflow:loss = 4.6864715, step = 4601 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.957\n",
      "INFO:tensorflow:loss = 0.81646216, step = 4701 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.321\n",
      "INFO:tensorflow:loss = 0.23823655, step = 4801 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.854\n",
      "INFO:tensorflow:loss = 0.4003966, step = 4901 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.953\n",
      "INFO:tensorflow:loss = 1.8824861, step = 5001 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.351\n",
      "INFO:tensorflow:loss = 0.5056133, step = 5101 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.966\n",
      "INFO:tensorflow:loss = 0.7445019, step = 5201 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.412\n",
      "INFO:tensorflow:loss = 0.37358236, step = 5301 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.794\n",
      "INFO:tensorflow:loss = 2.6473002, step = 5401 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.782\n",
      "INFO:tensorflow:loss = 5.3267074, step = 5501 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.746\n",
      "INFO:tensorflow:loss = 0.13580254, step = 5601 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.411\n",
      "INFO:tensorflow:loss = 0.8998982, step = 5701 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.733\n",
      "INFO:tensorflow:loss = 0.8287946, step = 5801 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.144\n",
      "INFO:tensorflow:loss = 0.22869375, step = 5901 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.587\n",
      "INFO:tensorflow:loss = 1.3593624, step = 6001 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.592\n",
      "INFO:tensorflow:loss = 0.54868174, step = 6101 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.701\n",
      "INFO:tensorflow:loss = 1.6849996, step = 6201 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.172\n",
      "INFO:tensorflow:loss = 0.7296839, step = 6301 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.564\n",
      "INFO:tensorflow:loss = 0.60183644, step = 6401 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.457\n",
      "INFO:tensorflow:loss = 1.433546, step = 6501 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.234\n",
      "INFO:tensorflow:loss = 2.7490788, step = 6601 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.178\n",
      "INFO:tensorflow:loss = 0.32260337, step = 6701 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.842\n",
      "INFO:tensorflow:loss = 11.059861, step = 6801 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.24\n",
      "INFO:tensorflow:loss = 0.28365695, step = 6901 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.625\n",
      "INFO:tensorflow:loss = 0.18816325, step = 7001 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5674726, step = 7101 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.039\n",
      "INFO:tensorflow:loss = 2.274275, step = 7201 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.424\n",
      "INFO:tensorflow:loss = 1.7583551, step = 7301 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.467\n",
      "INFO:tensorflow:loss = 0.156984, step = 7401 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.63\n",
      "INFO:tensorflow:loss = 0.6685974, step = 7501 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.986\n",
      "INFO:tensorflow:loss = 1.9742984, step = 7601 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.528\n",
      "INFO:tensorflow:loss = 0.42873287, step = 7701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.328\n",
      "INFO:tensorflow:loss = 0.50571597, step = 7801 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.129\n",
      "INFO:tensorflow:loss = 0.068235435, step = 7901 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.761\n",
      "INFO:tensorflow:loss = 0.18110281, step = 8001 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.276\n",
      "INFO:tensorflow:loss = 0.24691258, step = 8101 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.083\n",
      "INFO:tensorflow:loss = 1.6624999, step = 8201 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.755\n",
      "INFO:tensorflow:loss = 0.30661452, step = 8301 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.425\n",
      "INFO:tensorflow:loss = 0.72015214, step = 8401 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.842\n",
      "INFO:tensorflow:loss = 1.3874575, step = 8501 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.164\n",
      "INFO:tensorflow:loss = 0.22312686, step = 8601 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.544\n",
      "INFO:tensorflow:loss = 0.23380415, step = 8701 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.263\n",
      "INFO:tensorflow:loss = 0.41956264, step = 8801 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.805\n",
      "INFO:tensorflow:loss = 0.07741174, step = 8901 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.188\n",
      "INFO:tensorflow:loss = 0.60268587, step = 9001 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.537\n",
      "INFO:tensorflow:loss = 2.041042, step = 9101 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.946\n",
      "INFO:tensorflow:loss = 0.26430947, step = 9201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.793\n",
      "INFO:tensorflow:loss = 1.3699652, step = 9301 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.634\n",
      "INFO:tensorflow:loss = 0.8073608, step = 9401 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.034\n",
      "INFO:tensorflow:loss = 0.04672294, step = 9501 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.883\n",
      "INFO:tensorflow:loss = 0.31897536, step = 9601 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.823\n",
      "INFO:tensorflow:loss = 0.35882574, step = 9701 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.819\n",
      "INFO:tensorflow:loss = 0.21630815, step = 9801 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.616\n",
      "INFO:tensorflow:loss = 0.07393967, step = 9901 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.876\n",
      "INFO:tensorflow:loss = 0.9800434, step = 10001 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.64\n",
      "INFO:tensorflow:loss = 1.001855, step = 10101 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.813\n",
      "INFO:tensorflow:loss = 0.2664461, step = 10201 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.37\n",
      "INFO:tensorflow:loss = 0.08624038, step = 10301 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.041\n",
      "INFO:tensorflow:loss = 0.2682392, step = 10401 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.827\n",
      "INFO:tensorflow:loss = 0.21290481, step = 10501 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.72\n",
      "INFO:tensorflow:loss = 0.28307024, step = 10601 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.583\n",
      "INFO:tensorflow:loss = 0.6297672, step = 10701 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.416\n",
      "INFO:tensorflow:loss = 0.62933135, step = 10801 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.595\n",
      "INFO:tensorflow:loss = 0.21093638, step = 10901 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.809\n",
      "INFO:tensorflow:loss = 0.53121287, step = 11001 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.572\n",
      "INFO:tensorflow:loss = 0.6914542, step = 11101 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.112\n",
      "INFO:tensorflow:loss = 0.9606169, step = 11201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.524\n",
      "INFO:tensorflow:loss = 0.16228215, step = 11301 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.348\n",
      "INFO:tensorflow:loss = 0.3106733, step = 11401 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.462\n",
      "INFO:tensorflow:loss = 0.058105633, step = 11501 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.633\n",
      "INFO:tensorflow:loss = 0.10601471, step = 11601 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.547\n",
      "INFO:tensorflow:loss = 0.20602351, step = 11701 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.892\n",
      "INFO:tensorflow:loss = 0.7933006, step = 11801 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.434\n",
      "INFO:tensorflow:loss = 0.21994083, step = 11901 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.279\n",
      "INFO:tensorflow:loss = 0.5317627, step = 12001 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.828\n",
      "INFO:tensorflow:loss = 1.1546297, step = 12101 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.673\n",
      "INFO:tensorflow:loss = 0.04875194, step = 12201 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.309\n",
      "INFO:tensorflow:loss = 0.8300889, step = 12301 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.02\n",
      "INFO:tensorflow:loss = 0.64013857, step = 12401 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.763\n",
      "INFO:tensorflow:loss = 0.4395333, step = 12501 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.983\n",
      "INFO:tensorflow:loss = 0.021223173, step = 12601 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.488\n",
      "INFO:tensorflow:loss = 0.19816066, step = 12701 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.616\n",
      "INFO:tensorflow:loss = 0.12172602, step = 12801 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.099\n",
      "INFO:tensorflow:loss = 0.07936218, step = 12901 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.785\n",
      "INFO:tensorflow:loss = 0.019420013, step = 13001 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.457\n",
      "INFO:tensorflow:loss = 0.07290678, step = 13101 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.293\n",
      "INFO:tensorflow:loss = 0.1767155, step = 13201 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.968\n",
      "INFO:tensorflow:loss = 1.1097087, step = 13301 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.272\n",
      "INFO:tensorflow:loss = 0.053911984, step = 13401 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.303\n",
      "INFO:tensorflow:loss = 0.23629235, step = 13501 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.081\n",
      "INFO:tensorflow:loss = 0.093266815, step = 13601 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.296\n",
      "INFO:tensorflow:loss = 0.035793252, step = 13701 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.086\n",
      "INFO:tensorflow:loss = 0.0877766, step = 13801 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.817\n",
      "INFO:tensorflow:loss = 0.1325406, step = 13901 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.309\n",
      "INFO:tensorflow:loss = 0.05610048, step = 14001 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.379\n",
      "INFO:tensorflow:loss = 0.06457304, step = 14101 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.248\n",
      "INFO:tensorflow:loss = 0.06991201, step = 14201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.515\n",
      "INFO:tensorflow:loss = 0.029011449, step = 14301 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.991\n",
      "INFO:tensorflow:loss = 0.2340396, step = 14401 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.986\n",
      "INFO:tensorflow:loss = 0.14168014, step = 14501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.949\n",
      "INFO:tensorflow:loss = 0.14088945, step = 14601 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.115\n",
      "INFO:tensorflow:loss = 0.22566193, step = 14701 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.083\n",
      "INFO:tensorflow:loss = 0.20753302, step = 14801 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.756\n",
      "INFO:tensorflow:loss = 0.16725183, step = 14901 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.673\n",
      "INFO:tensorflow:loss = 0.22775789, step = 15001 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.309\n",
      "INFO:tensorflow:loss = 0.18925259, step = 15101 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.879\n",
      "INFO:tensorflow:loss = 0.057089277, step = 15201 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.20947191, step = 15301 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.624\n",
      "INFO:tensorflow:loss = 0.42463732, step = 15401 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.322\n",
      "INFO:tensorflow:loss = 0.28753346, step = 15501 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.079\n",
      "INFO:tensorflow:loss = 0.08303131, step = 15601 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.998\n",
      "INFO:tensorflow:loss = 0.008072927, step = 15701 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.549\n",
      "INFO:tensorflow:loss = 0.09134287, step = 15801 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.558\n",
      "INFO:tensorflow:loss = 0.06701621, step = 15901 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.208\n",
      "INFO:tensorflow:loss = 0.13443042, step = 16001 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.258\n",
      "INFO:tensorflow:loss = 0.014623586, step = 16101 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.695\n",
      "INFO:tensorflow:loss = 0.10144234, step = 16201 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.168\n",
      "INFO:tensorflow:loss = 0.07909022, step = 16301 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.883\n",
      "INFO:tensorflow:loss = 0.90618825, step = 16401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.632\n",
      "INFO:tensorflow:loss = 0.35038742, step = 16501 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.123\n",
      "INFO:tensorflow:loss = 0.17348178, step = 16601 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.102\n",
      "INFO:tensorflow:loss = 0.032507434, step = 16701 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.035\n",
      "INFO:tensorflow:loss = 0.2978894, step = 16801 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.028\n",
      "INFO:tensorflow:loss = 0.045553584, step = 16901 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.015\n",
      "INFO:tensorflow:loss = 0.07956776, step = 17001 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.285\n",
      "INFO:tensorflow:loss = 0.10162478, step = 17101 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.198\n",
      "INFO:tensorflow:loss = 0.14435737, step = 17201 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.512\n",
      "INFO:tensorflow:loss = 0.048766833, step = 17301 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.246\n",
      "INFO:tensorflow:loss = 0.018991515, step = 17401 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.049\n",
      "INFO:tensorflow:loss = 0.0031490186, step = 17501 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.869\n",
      "INFO:tensorflow:loss = 0.021353602, step = 17601 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.921\n",
      "INFO:tensorflow:loss = 0.12358394, step = 17701 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.295\n",
      "INFO:tensorflow:loss = 0.11272363, step = 17801 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.45\n",
      "INFO:tensorflow:loss = 0.04189821, step = 17901 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.874\n",
      "INFO:tensorflow:loss = 0.0036602756, step = 18001 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.869\n",
      "INFO:tensorflow:loss = 0.010505608, step = 18101 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.584\n",
      "INFO:tensorflow:loss = 0.053997163, step = 18201 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.936\n",
      "INFO:tensorflow:loss = 0.08924629, step = 18301 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.437\n",
      "INFO:tensorflow:loss = 0.1165624, step = 18401 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.956\n",
      "INFO:tensorflow:loss = 0.07432291, step = 18501 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.125\n",
      "INFO:tensorflow:loss = 0.10852886, step = 18601 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.565\n",
      "INFO:tensorflow:loss = 0.04460764, step = 18701 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.154\n",
      "INFO:tensorflow:loss = 0.012164235, step = 18801 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.346\n",
      "INFO:tensorflow:loss = 0.097387105, step = 18901 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.226\n",
      "INFO:tensorflow:loss = 0.098395124, step = 19001 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.725\n",
      "INFO:tensorflow:loss = 0.043218303, step = 19101 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.022\n",
      "INFO:tensorflow:loss = 0.30055907, step = 19201 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.554\n",
      "INFO:tensorflow:loss = 0.07259923, step = 19301 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.877\n",
      "INFO:tensorflow:loss = 0.03858875, step = 19401 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.519\n",
      "INFO:tensorflow:loss = 0.08697297, step = 19501 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.059\n",
      "INFO:tensorflow:loss = 0.03932728, step = 19601 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.269\n",
      "INFO:tensorflow:loss = 0.11115246, step = 19701 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.99\n",
      "INFO:tensorflow:loss = 0.05058665, step = 19801 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.408\n",
      "INFO:tensorflow:loss = 0.048553918, step = 19901 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.026\n",
      "INFO:tensorflow:loss = 0.036594644, step = 20001 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.051\n",
      "INFO:tensorflow:loss = 0.064473584, step = 20101 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.742\n",
      "INFO:tensorflow:loss = 0.09213179, step = 20201 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.543\n",
      "INFO:tensorflow:loss = 0.015409195, step = 20301 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.546\n",
      "INFO:tensorflow:loss = 0.039011978, step = 20401 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.463\n",
      "INFO:tensorflow:loss = 0.12809834, step = 20501 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.429\n",
      "INFO:tensorflow:loss = 0.033537723, step = 20601 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.559\n",
      "INFO:tensorflow:loss = 0.10030449, step = 20701 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.853\n",
      "INFO:tensorflow:loss = 0.020293728, step = 20801 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.832\n",
      "INFO:tensorflow:loss = 0.19892308, step = 20901 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.363\n",
      "INFO:tensorflow:loss = 0.007296324, step = 21001 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.666\n",
      "INFO:tensorflow:loss = 0.020849189, step = 21101 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.058\n",
      "INFO:tensorflow:loss = 0.019600471, step = 21201 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.894\n",
      "INFO:tensorflow:loss = 0.035384756, step = 21301 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.708\n",
      "INFO:tensorflow:loss = 0.076832, step = 21401 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.282\n",
      "INFO:tensorflow:loss = 0.04026574, step = 21501 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.514\n",
      "INFO:tensorflow:loss = 0.011676377, step = 21601 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.829\n",
      "INFO:tensorflow:loss = 0.057145517, step = 21701 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.477\n",
      "INFO:tensorflow:loss = 0.009757092, step = 21801 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.763\n",
      "INFO:tensorflow:loss = 0.030065209, step = 21901 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.076\n",
      "INFO:tensorflow:loss = 0.082248256, step = 22001 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.817\n",
      "INFO:tensorflow:loss = 0.10670948, step = 22101 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.474\n",
      "INFO:tensorflow:loss = 0.009501696, step = 22201 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.322\n",
      "INFO:tensorflow:loss = 0.09296917, step = 22301 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.34\n",
      "INFO:tensorflow:loss = 0.037645448, step = 22401 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.871\n",
      "INFO:tensorflow:loss = 0.10375924, step = 22501 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.108\n",
      "INFO:tensorflow:loss = 0.072130755, step = 22601 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.085\n",
      "INFO:tensorflow:loss = 0.094182774, step = 22701 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.923\n",
      "INFO:tensorflow:loss = 0.07395862, step = 22801 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.097\n",
      "INFO:tensorflow:loss = 0.08135694, step = 22901 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.322\n",
      "INFO:tensorflow:loss = 0.03846724, step = 23001 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 418\n",
      "INFO:tensorflow:loss = 0.1016888, step = 23101 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.093\n",
      "INFO:tensorflow:loss = 0.052272007, step = 23201 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.566\n",
      "INFO:tensorflow:loss = 0.07754504, step = 23301 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.035269815, step = 23401 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.829\n",
      "INFO:tensorflow:loss = 0.04378336, step = 23501 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.964\n",
      "INFO:tensorflow:loss = 0.07447075, step = 23601 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.474\n",
      "INFO:tensorflow:loss = 0.06242025, step = 23701 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.641\n",
      "INFO:tensorflow:loss = 0.007561949, step = 23801 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.429\n",
      "INFO:tensorflow:loss = 0.006210351, step = 23901 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.142\n",
      "INFO:tensorflow:loss = 0.09106745, step = 24001 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.191\n",
      "INFO:tensorflow:loss = 0.04791251, step = 24101 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.343\n",
      "INFO:tensorflow:loss = 0.008329669, step = 24201 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.54\n",
      "INFO:tensorflow:loss = 0.073965415, step = 24301 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.269\n",
      "INFO:tensorflow:loss = 0.048143204, step = 24401 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.718\n",
      "INFO:tensorflow:loss = 0.038130786, step = 24501 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.343\n",
      "INFO:tensorflow:loss = 0.042858236, step = 24601 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.296\n",
      "INFO:tensorflow:loss = 0.0025403309, step = 24701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.28\n",
      "INFO:tensorflow:loss = 0.007825682, step = 24801 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.875\n",
      "INFO:tensorflow:loss = 0.04597418, step = 24901 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.557\n",
      "INFO:tensorflow:loss = 0.019168252, step = 25001 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.046\n",
      "INFO:tensorflow:loss = 0.01556286, step = 25101 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.002\n",
      "INFO:tensorflow:loss = 0.017276824, step = 25201 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.356\n",
      "INFO:tensorflow:loss = 0.014230155, step = 25301 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.818\n",
      "INFO:tensorflow:loss = 0.0032718112, step = 25401 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.839\n",
      "INFO:tensorflow:loss = 0.043708816, step = 25501 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.243\n",
      "INFO:tensorflow:loss = 0.01397725, step = 25601 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.725\n",
      "INFO:tensorflow:loss = 0.06304489, step = 25701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.077\n",
      "INFO:tensorflow:loss = 0.024361165, step = 25801 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.004\n",
      "INFO:tensorflow:loss = 0.01278522, step = 25901 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.494\n",
      "INFO:tensorflow:loss = 0.06268806, step = 26001 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.653\n",
      "INFO:tensorflow:loss = 0.0040501477, step = 26101 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.236\n",
      "INFO:tensorflow:loss = 0.0052282056, step = 26201 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.704\n",
      "INFO:tensorflow:loss = 0.10650485, step = 26301 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.942\n",
      "INFO:tensorflow:loss = 0.03879466, step = 26401 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.968\n",
      "INFO:tensorflow:loss = 0.034968987, step = 26501 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.385\n",
      "INFO:tensorflow:loss = 0.026192667, step = 26601 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.474\n",
      "INFO:tensorflow:loss = 0.021162663, step = 26701 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.153\n",
      "INFO:tensorflow:loss = 0.038060132, step = 26801 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.909\n",
      "INFO:tensorflow:loss = 0.14700375, step = 26901 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.63\n",
      "INFO:tensorflow:loss = 0.0045643994, step = 27001 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.351\n",
      "INFO:tensorflow:loss = 0.07663628, step = 27101 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.138\n",
      "INFO:tensorflow:loss = 0.0029102752, step = 27201 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.022\n",
      "INFO:tensorflow:loss = 0.05871891, step = 27301 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.866\n",
      "INFO:tensorflow:loss = 0.058896527, step = 27401 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.338\n",
      "INFO:tensorflow:loss = 0.055377923, step = 27501 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.282\n",
      "INFO:tensorflow:loss = 0.0039064377, step = 27601 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.659\n",
      "INFO:tensorflow:loss = 0.19032526, step = 27701 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.283\n",
      "INFO:tensorflow:loss = 0.009486159, step = 27801 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.209\n",
      "INFO:tensorflow:loss = 0.05507209, step = 27901 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.959\n",
      "INFO:tensorflow:loss = 0.018757565, step = 28001 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.251\n",
      "INFO:tensorflow:loss = 0.016419593, step = 28101 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.603\n",
      "INFO:tensorflow:loss = 0.0011001737, step = 28201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.503\n",
      "INFO:tensorflow:loss = 0.014902489, step = 28301 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.546\n",
      "INFO:tensorflow:loss = 0.018868644, step = 28401 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.942\n",
      "INFO:tensorflow:loss = 0.09442868, step = 28501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.077\n",
      "INFO:tensorflow:loss = 0.054228075, step = 28601 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.239\n",
      "INFO:tensorflow:loss = 0.007987767, step = 28701 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.157\n",
      "INFO:tensorflow:loss = 0.10392774, step = 28801 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.165\n",
      "INFO:tensorflow:loss = 0.009911036, step = 28901 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.874\n",
      "INFO:tensorflow:loss = 0.034026146, step = 29001 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.1\n",
      "INFO:tensorflow:loss = 0.02539852, step = 29101 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.754\n",
      "INFO:tensorflow:loss = 0.0045135724, step = 29201 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.024\n",
      "INFO:tensorflow:loss = 0.064779505, step = 29301 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.577\n",
      "INFO:tensorflow:loss = 0.03388282, step = 29401 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.418\n",
      "INFO:tensorflow:loss = 0.025490971, step = 29501 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.357\n",
      "INFO:tensorflow:loss = 0.04964648, step = 29601 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.87\n",
      "INFO:tensorflow:loss = 0.06958798, step = 29701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.117\n",
      "INFO:tensorflow:loss = 0.06713562, step = 29801 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.71\n",
      "INFO:tensorflow:loss = 0.035048567, step = 29901 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.475\n",
      "INFO:tensorflow:loss = 0.005095091, step = 30001 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.926\n",
      "INFO:tensorflow:loss = 0.00073518907, step = 30101 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.038\n",
      "INFO:tensorflow:loss = 0.04819914, step = 30201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.431\n",
      "INFO:tensorflow:loss = 0.0061301263, step = 30301 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.643\n",
      "INFO:tensorflow:loss = 0.012906715, step = 30401 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.921\n",
      "INFO:tensorflow:loss = 0.02677796, step = 30501 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.287\n",
      "INFO:tensorflow:loss = 0.06077624, step = 30601 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.94\n",
      "INFO:tensorflow:loss = 0.023358148, step = 30701 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.156\n",
      "INFO:tensorflow:loss = 0.009021723, step = 30801 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.452\n",
      "INFO:tensorflow:loss = 0.06119623, step = 30901 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.432\n",
      "INFO:tensorflow:loss = 0.047363564, step = 31001 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.747\n",
      "INFO:tensorflow:loss = 0.022963827, step = 31101 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.829\n",
      "INFO:tensorflow:loss = 0.021344809, step = 31201 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.489\n",
      "INFO:tensorflow:loss = 0.002673825, step = 31301 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.916\n",
      "INFO:tensorflow:loss = 0.019881492, step = 31401 (0.223 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 261.624\n",
      "INFO:tensorflow:loss = 0.021626325, step = 31501 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.537\n",
      "INFO:tensorflow:loss = 0.038797334, step = 31601 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.819\n",
      "INFO:tensorflow:loss = 0.007930952, step = 31701 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.78\n",
      "INFO:tensorflow:loss = 0.049187273, step = 31801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.669\n",
      "INFO:tensorflow:loss = 0.013475981, step = 31901 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.865\n",
      "INFO:tensorflow:loss = 0.024584394, step = 32001 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.98\n",
      "INFO:tensorflow:loss = 0.027538313, step = 32101 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.078\n",
      "INFO:tensorflow:loss = 0.04601989, step = 32201 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.649\n",
      "INFO:tensorflow:loss = 0.004689388, step = 32301 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.359\n",
      "INFO:tensorflow:loss = 0.010100246, step = 32401 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.954\n",
      "INFO:tensorflow:loss = 0.042082623, step = 32501 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.456\n",
      "INFO:tensorflow:loss = 0.03607741, step = 32601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.141\n",
      "INFO:tensorflow:loss = 0.07325846, step = 32701 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.449\n",
      "INFO:tensorflow:loss = 0.030807242, step = 32801 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.58\n",
      "INFO:tensorflow:loss = 0.01266159, step = 32901 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.507\n",
      "INFO:tensorflow:loss = 0.0035090775, step = 33001 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.64\n",
      "INFO:tensorflow:loss = 0.008255615, step = 33101 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.454\n",
      "INFO:tensorflow:loss = 0.004388163, step = 33201 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.236\n",
      "INFO:tensorflow:loss = 0.0036278549, step = 33301 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.768\n",
      "INFO:tensorflow:loss = 0.009721316, step = 33401 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.905\n",
      "INFO:tensorflow:loss = 0.06617722, step = 33501 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.566\n",
      "INFO:tensorflow:loss = 0.014821098, step = 33601 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.292\n",
      "INFO:tensorflow:loss = 0.049137097, step = 33701 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.363\n",
      "INFO:tensorflow:loss = 0.033024617, step = 33801 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.795\n",
      "INFO:tensorflow:loss = 0.01808234, step = 33901 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.269\n",
      "INFO:tensorflow:loss = 0.078217804, step = 34001 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.939\n",
      "INFO:tensorflow:loss = 0.036776863, step = 34101 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.368\n",
      "INFO:tensorflow:loss = 0.035833415, step = 34201 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.139\n",
      "INFO:tensorflow:loss = 0.026956836, step = 34301 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.468\n",
      "INFO:tensorflow:loss = 0.04379407, step = 34401 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.192\n",
      "INFO:tensorflow:loss = 0.015772937, step = 34501 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.814\n",
      "INFO:tensorflow:loss = 0.0049835956, step = 34601 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.672\n",
      "INFO:tensorflow:loss = 0.0021316775, step = 34701 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.946\n",
      "INFO:tensorflow:loss = 0.0146868965, step = 34801 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.463\n",
      "INFO:tensorflow:loss = 0.03667141, step = 34901 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.824\n",
      "INFO:tensorflow:loss = 0.059297964, step = 35001 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.881\n",
      "INFO:tensorflow:loss = 0.1066694, step = 35101 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.153\n",
      "INFO:tensorflow:loss = 0.00405618, step = 35201 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.58\n",
      "INFO:tensorflow:loss = 0.007927811, step = 35301 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.203\n",
      "INFO:tensorflow:loss = 0.020046333, step = 35401 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.849\n",
      "INFO:tensorflow:loss = 0.029836655, step = 35501 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.244\n",
      "INFO:tensorflow:loss = 0.010308577, step = 35601 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.667\n",
      "INFO:tensorflow:loss = 0.012216505, step = 35701 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.178\n",
      "INFO:tensorflow:loss = 0.019427737, step = 35801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.167\n",
      "INFO:tensorflow:loss = 0.012125941, step = 35901 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.216\n",
      "INFO:tensorflow:loss = 0.012279984, step = 36001 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.515\n",
      "INFO:tensorflow:loss = 0.0035381226, step = 36101 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.493\n",
      "INFO:tensorflow:loss = 0.10475298, step = 36201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.515\n",
      "INFO:tensorflow:loss = 0.032026708, step = 36301 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.746\n",
      "INFO:tensorflow:loss = 0.011585275, step = 36401 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.61\n",
      "INFO:tensorflow:loss = 0.050019354, step = 36501 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.915\n",
      "INFO:tensorflow:loss = 0.0054973303, step = 36601 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.091\n",
      "INFO:tensorflow:loss = 0.030477237, step = 36701 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.643\n",
      "INFO:tensorflow:loss = 0.045059077, step = 36801 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.588\n",
      "INFO:tensorflow:loss = 0.0063012196, step = 36901 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.886\n",
      "INFO:tensorflow:loss = 0.009071657, step = 37001 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.751\n",
      "INFO:tensorflow:loss = 0.0010020111, step = 37101 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.683\n",
      "INFO:tensorflow:loss = 0.006070201, step = 37201 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.642\n",
      "INFO:tensorflow:loss = 0.021293255, step = 37301 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.092\n",
      "INFO:tensorflow:loss = 0.0034095226, step = 37401 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.973\n",
      "INFO:tensorflow:loss = 0.008701416, step = 37501 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.709\n",
      "INFO:tensorflow:loss = 0.019817196, step = 37601 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.306\n",
      "INFO:tensorflow:loss = 0.0010544525, step = 37701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.581\n",
      "INFO:tensorflow:loss = 0.0056092944, step = 37801 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.744\n",
      "INFO:tensorflow:loss = 0.009612068, step = 37901 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.253\n",
      "INFO:tensorflow:loss = 0.0048049195, step = 38001 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.922\n",
      "INFO:tensorflow:loss = 0.0111874305, step = 38101 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.044\n",
      "INFO:tensorflow:loss = 0.020530282, step = 38201 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.171\n",
      "INFO:tensorflow:loss = 0.0081350375, step = 38301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.189\n",
      "INFO:tensorflow:loss = 0.01462291, step = 38401 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.048\n",
      "INFO:tensorflow:loss = 0.0075869625, step = 38501 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.713\n",
      "INFO:tensorflow:loss = 0.009341433, step = 38601 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.817\n",
      "INFO:tensorflow:loss = 0.0015583445, step = 38701 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.366\n",
      "INFO:tensorflow:loss = 0.0012186025, step = 38801 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.204\n",
      "INFO:tensorflow:loss = 0.0066072466, step = 38901 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.126\n",
      "INFO:tensorflow:loss = 0.00962773, step = 39001 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.675\n",
      "INFO:tensorflow:loss = 0.032980565, step = 39101 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.027\n",
      "INFO:tensorflow:loss = 0.02825882, step = 39201 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.892\n",
      "INFO:tensorflow:loss = 0.008006116, step = 39301 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.847\n",
      "INFO:tensorflow:loss = 0.011292361, step = 39401 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.031466037, step = 39501 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.98\n",
      "INFO:tensorflow:loss = 0.0018573137, step = 39601 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.296\n",
      "INFO:tensorflow:loss = 0.025803728, step = 39701 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.905\n",
      "INFO:tensorflow:loss = 0.008109973, step = 39801 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.544\n",
      "INFO:tensorflow:loss = 0.008321383, step = 39901 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.123\n",
      "INFO:tensorflow:loss = 0.0029288158, step = 40001 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.605\n",
      "INFO:tensorflow:loss = 0.0039622616, step = 40101 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.338\n",
      "INFO:tensorflow:loss = 0.0070899157, step = 40201 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.007\n",
      "INFO:tensorflow:loss = 0.022529049, step = 40301 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.846\n",
      "INFO:tensorflow:loss = 0.0022286123, step = 40401 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.958\n",
      "INFO:tensorflow:loss = 0.045648623, step = 40501 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.243\n",
      "INFO:tensorflow:loss = 0.021253653, step = 40601 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.3\n",
      "INFO:tensorflow:loss = 0.01822092, step = 40701 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.655\n",
      "INFO:tensorflow:loss = 0.0017353436, step = 40801 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.697\n",
      "INFO:tensorflow:loss = 0.0014262099, step = 40901 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.822\n",
      "INFO:tensorflow:loss = 0.024405029, step = 41001 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.807\n",
      "INFO:tensorflow:loss = 0.0081441, step = 41101 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.635\n",
      "INFO:tensorflow:loss = 0.01027826, step = 41201 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.495\n",
      "INFO:tensorflow:loss = 0.00018476608, step = 41301 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.597\n",
      "INFO:tensorflow:loss = 0.02499907, step = 41401 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.887\n",
      "INFO:tensorflow:loss = 0.0013607775, step = 41501 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.532\n",
      "INFO:tensorflow:loss = 0.004924154, step = 41601 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.92\n",
      "INFO:tensorflow:loss = 0.008655722, step = 41701 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.279\n",
      "INFO:tensorflow:loss = 0.024336375, step = 41801 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.288\n",
      "INFO:tensorflow:loss = 0.010536734, step = 41901 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.995\n",
      "INFO:tensorflow:loss = 0.0025605336, step = 42001 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.531\n",
      "INFO:tensorflow:loss = 0.0032093476, step = 42101 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.077\n",
      "INFO:tensorflow:loss = 0.012515508, step = 42201 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.366\n",
      "INFO:tensorflow:loss = 0.021701053, step = 42301 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.217\n",
      "INFO:tensorflow:loss = 0.0011699339, step = 42401 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.5\n",
      "INFO:tensorflow:loss = 0.030998865, step = 42501 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.818\n",
      "INFO:tensorflow:loss = 0.0072836773, step = 42601 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.745\n",
      "INFO:tensorflow:loss = 0.019705372, step = 42701 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.799\n",
      "INFO:tensorflow:loss = 0.016950145, step = 42801 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.539\n",
      "INFO:tensorflow:loss = 0.027115647, step = 42901 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.097\n",
      "INFO:tensorflow:loss = 0.010983186, step = 43001 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.309\n",
      "INFO:tensorflow:loss = 0.010593252, step = 43101 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.3\n",
      "INFO:tensorflow:loss = 0.03340333, step = 43201 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.402\n",
      "INFO:tensorflow:loss = 0.021518689, step = 43301 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.886\n",
      "INFO:tensorflow:loss = 0.0114959255, step = 43401 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.951\n",
      "INFO:tensorflow:loss = 0.024620455, step = 43501 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.308\n",
      "INFO:tensorflow:loss = 0.009099324, step = 43601 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.256\n",
      "INFO:tensorflow:loss = 0.008355641, step = 43701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.168\n",
      "INFO:tensorflow:loss = 0.008354376, step = 43801 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.602\n",
      "INFO:tensorflow:loss = 0.0063730236, step = 43901 (0.232 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44000 into /var/folders/pz/0k_47k855d194vh0354xcvrc0000gn/T/tmpuuj_bihh/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.004377368.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x11b473278>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column('X', shape=[28 * 28])]\n",
    "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[300, 100], n_classes=10, feature_columns=feature_cols)\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(x={\"X\": X_train}, y=y_train, num_epochs=40, batch_size=50,\n",
    "                                              shuffle=True)\n",
    "dnn_clf.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code first creates a set of real valued columns from the training set. Then we create the `DNNClassifier` and we wrap it in a sklearn compatibility helper. Finally, we run 40,000 training iterations using batches of 50 instances. If you run this code on the dataset after scaling it, you'll get a model that achieves around 98.2% accuracy on the test set!\n",
    "\n",
    "Under the hood, the `DNNClassifier` class creates all the neuron layers based on the ReLU activation function (we can change this by setting the `activation_fn` hyperparameter). The output layer relies on softmax, and the cost function is cross entropy (from chapter 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-18-07:21:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/pz/0k_47k855d194vh0354xcvrc0000gn/T/tmpuuj_bihh/model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-18-07:21:01\n",
      "INFO:tensorflow:Saving dict for global step 44000: accuracy = 0.98, average_loss = 0.10085638, global_step = 44000, loss = 12.76663\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 44000: /var/folders/pz/0k_47k855d194vh0354xcvrc0000gn/T/tmpuuj_bihh/model.ckpt-44000\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results = dnn_clf.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.98,\n",
       " 'average_loss': 0.10085638,\n",
       " 'loss': 12.76663,\n",
       " 'global_step': 44000}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/pz/0k_47k855d194vh0354xcvrc0000gn/T/tmpuuj_bihh/model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "y_pred_iter = dnn_clf.predict(input_fn=test_input_fn)\n",
    "y_pred = list(y_pred_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use Keras for this task. The code would look like the following:\n",
    "\n",
    "```\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(300, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DNN Using Plain TensorFlow\n",
    "\n",
    "If you want more control over the architecture of the network, you may prefer to use TensorFlow's lower-level Python API. We'll build the same model as above using this API implementing mini-batch gradient descent to train it on the MNIST dataset.\n",
    "\n",
    "Step 1 is building the graph in the construction phase, and step two is the execution phase where we run the graph to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Phase\n",
    "\n",
    "First, we need to specify the inputs and outputs and set the number of hidden neurons in each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder nodes will represent the training data and the targets. We're only partially defining the shape of __X__ cause we know it'll be a 2D matrix with instances along the first dimension and features along the second, and we know we'll have one feature per pixel for 784 features, but we don't know how many instances the training batches will contain. Hence the shape must be `(None, n_inputs)`. Similarly, we know that `y` will be a 1D tensor with one entry per instance, but we don't know sizes so the shape must be `(None)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create placeholders\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the ANN. `X` will act as the input layer; during the execution phase, it will be replaced with one training batch at a time *note that ll instance in a training batch will be processed simultaneously by the neural net).* Now you need to create the two hidden layers and the output layer. The two hidden layers will really only differ by the inputs they're connected to and the number of neurons, and the output layer will be softmax instead of ReLU. Time to write a function for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        std_dev = 2 / np.sqrt(n_inputs + n_neurons)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=std_dev)\n",
    "        W = tf.Variable(init, name='kernel')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name='bias')\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        \n",
    "        return activation(Z) if activation is not None else Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break the code down line by line:\n",
    "\n",
    "1) Create a namescope using the name of the layer; it will contain all of the computation nodes for this neuron layer. This is optional, but the graph will look much nicer in TensorBoard if the nodes are well organized.\n",
    "\n",
    "2) Get the number of inputs by looking up the input matrix's shape and getting the size of the second dimension (first is for instances)\n",
    "\n",
    "3) Next three lines create a `W` variable that will hold the weights matrix (often called the *kernel* of the layer). It will be a 2D matrix containing all the connection weights between each input and each neuron; hense, its shape will be (n_inputs, n_neurons). It'll be randomly initialized using a truncated Gaussian distribution with standard deviation of $\\frac{2}{\\sqrt{n_{\\text{inputs}} + n_{\\text{neurons}}}}$ Using this specific standard deviation helps the algo converge must faster (more to come in chapter 11). It's important to initialize connection weights randomly for all hidden layers to avoid any symmetries that Gradient Descent wouldn't be able to break.\n",
    "\n",
    "4) The nxt line creates a `b` variable for biases, initialized to 0 (no syhmmetry issue in this case) with one bias param per neuron.\n",
    "\n",
    "5) WE create a subgraph to compute $\\textbf{Z} = \\textbf{X} \\cdot \\textbf{W} + \\textbf{b}$. This vectorized implementation will efficiently compute the weighted sums of the inputs plus the bias term for each and every neuron in the layer, for all instanes in the batch in just one shot. *Note: adding a 1D array to a 2D matrix with the same number of columns results in the 1D array being added to every row in the matrix. This is known as *broadcasting*\n",
    "\n",
    "6) Finally, if an `activation` param is provided such as `tf.nn.relu`, then the code returns `activation(Z)` otherwise it returns just `Z`.\n",
    "\n",
    "Okay so we can create a layer, so let's make a network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name='hidden1', activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name='hidden2', activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name='outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that `logits` is the output __before__ going through softmax activation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
